{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3d684f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8033456b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.7.11 (default, Jul 27 2021, 09:42:29) [MSC v.1916 64 bit (AMD64)]'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7507b637",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import csv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd2c02ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bert-tensorflow in c:\\users\\u1111995\\.conda\\envs\\python\\lib\\site-packages (1.0.4)\n",
      "Requirement already satisfied: six in c:\\users\\u1111995\\.conda\\envs\\python\\lib\\site-packages (from bert-tensorflow) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install bert-tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bcdaddb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bert import modeling\n",
    "from bert import optimization\n",
    "from bert import tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ab27808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow==1.15.4 in c:\\users\\u1111995\\.conda\\envs\\python\\lib\\site-packages (1.15.4)\n",
      "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in c:\\users\\u1111995\\.conda\\envs\\python\\lib\\site-packages (from tensorflow==1.15.4) (1.15.0)\n",
      "Requirement already satisfied: six>=1.10.0 in c:\\users\\u1111995\\.conda\\envs\\python\\lib\\site-packages (from tensorflow==1.15.4) (1.16.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in c:\\users\\u1111995\\.conda\\envs\\python\\lib\\site-packages (from tensorflow==1.15.4) (1.13.3)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in c:\\users\\u1111995\\.conda\\envs\\python\\lib\\site-packages (from tensorflow==1.15.4) (1.1.2)\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\users\\u1111995\\.conda\\envs\\python\\lib\\site-packages (from tensorflow==1.15.4) (0.37.1)\n",
      "Requirement already satisfied: gast==0.2.2 in c:\\users\\u1111995\\.conda\\envs\\python\\lib\\site-packages (from tensorflow==1.15.4) (0.2.2)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\u1111995\\.conda\\envs\\python\\lib\\site-packages (from tensorflow==1.15.4) (1.1.0)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in c:\\users\\u1111995\\.conda\\envs\\python\\lib\\site-packages (from tensorflow==1.15.4) (3.19.1)\n",
      "Requirement already satisfied: keras-applications>=1.0.8 in c:\\users\\u1111995\\.conda\\envs\\python\\lib\\site-packages (from tensorflow==1.15.4) (1.0.8)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in c:\\users\\u1111995\\.conda\\envs\\python\\lib\\site-packages (from tensorflow==1.15.4) (1.43.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in c:\\users\\u1111995\\.conda\\envs\\python\\lib\\site-packages (from tensorflow==1.15.4) (0.2.0)\n",
      "Requirement already satisfied: numpy<1.19.0,>=1.16.0 in c:\\users\\u1111995\\.conda\\envs\\python\\lib\\site-packages (from tensorflow==1.15.4) (1.18.5)\n",
      "Requirement already satisfied: astor>=0.6.0 in c:\\users\\u1111995\\.conda\\envs\\python\\lib\\site-packages (from tensorflow==1.15.4) (0.8.1)\n",
      "Requirement already satisfied: tensorflow-estimator==1.15.1 in c:\\users\\u1111995\\.conda\\envs\\python\\lib\\site-packages (from tensorflow==1.15.4) (1.15.1)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in c:\\users\\u1111995\\.conda\\envs\\python\\lib\\site-packages (from tensorflow==1.15.4) (1.0.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\u1111995\\.conda\\envs\\python\\lib\\site-packages (from tensorflow==1.15.4) (3.3.0)\n",
      "Requirement already satisfied: h5py in c:\\users\\u1111995\\.conda\\envs\\python\\lib\\site-packages (from keras-applications>=1.0.8->tensorflow==1.15.4) (3.6.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\u1111995\\.conda\\envs\\python\\lib\\site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.4) (60.2.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\u1111995\\.conda\\envs\\python\\lib\\site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.4) (3.3.6)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\u1111995\\.conda\\envs\\python\\lib\\site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.4) (0.16.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\u1111995\\.conda\\envs\\python\\lib\\site-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.4) (4.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in c:\\users\\u1111995\\.conda\\envs\\python\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.4) (3.10.0.2)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\u1111995\\.conda\\envs\\python\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.4) (3.7.0)\n",
      "Requirement already satisfied: cached-property in c:\\users\\u1111995\\.conda\\envs\\python\\lib\\site-packages (from h5py->keras-applications>=1.0.8->tensorflow==1.15.4) (1.5.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow==1.15.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9919616",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from ipynb.fs.full.tokenization import *\n",
    "#from ipynb.fs.full.modeling import *\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23818858",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.15.4\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "293d21af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy==1.18.5 in c:\\users\\u1111995\\.conda\\envs\\python\\lib\\site-packages (1.18.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy==1.18.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d1728a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.18.5'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy\n",
    "numpy.version.version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5c045d",
   "metadata": {},
   "source": [
    "###### Using Dictionary to initialize values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e92b96",
   "metadata": {},
   "source": [
    "###### Flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98133df3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<absl.flags._flagvalues.FlagHolder at 0x1490f29adc8>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flags = tf.flags\n",
    "\n",
    "FLAGS = flags.FLAGS\n",
    "\n",
    "flags.DEFINE_string(\n",
    "    \"bert_config_file\",\"bert_config.json\",\n",
    "    \"The config json file corresponding to the pre-trained BERT model. \"\n",
    "    \"This specifies the model architecture.\")\n",
    "\n",
    "\n",
    "flags.DEFINE_string(\"vocab_file\",\"vocab.txt\",\"The vocabulary file that the BERT model was trained on.\")\n",
    "\n",
    "\n",
    "#Other parameters\n",
    "\n",
    "flags.DEFINE_string(\n",
    "    \"init_checkpoint\",\"bert_model.ckpt\",\n",
    "    \"Initial checkpoint (usually from a pre-trained BERT model).\")\n",
    "\n",
    "flags.DEFINE_bool(\n",
    "    \"do_lower_case\", True,\n",
    "    \"Whether to lower case the input text. Should be True for uncased \"\n",
    "    \"models and False for cased models.\")\n",
    "\n",
    "flags.DEFINE_integer(\n",
    "    \"max_seq_length\",512,\n",
    "    \"The maximum total input sequence length after WordPiece tokenization. \"\n",
    "    \"Sequences longer than this will be truncated, and sequences shorter \"\n",
    "    \"than this will be padded.\")\n",
    "\n",
    "flags.DEFINE_bool(\"do_train\",True, \"Whether to run training.\")\n",
    "\n",
    "flags.DEFINE_bool(\"do_eval\",True, \"Whether to run eval on the dev set.\")\n",
    "\n",
    "flags.DEFINE_bool(\n",
    "    \"do_predict\",True,\n",
    "    \"Whether to run the model in inference mode on the test set.\")\n",
    "\n",
    "flags.DEFINE_integer(\"train_batch_size\", 4, \"Total batch size for training.\")\n",
    "\n",
    "flags.DEFINE_integer(\"eval_batch_size\", 8, \"Total batch size for eval.\")\n",
    "\n",
    "flags.DEFINE_integer(\"predict_batch_size\", 8, \"Total batch size for predict.\")\n",
    "\n",
    "flags.DEFINE_float(\"learning_rate\", 2e-5, \"The initial learning rate for Adam.\")\n",
    "\n",
    "flags.DEFINE_float(\"num_train_epochs\", 3.0,\n",
    "                   \"Total number of training epochs to perform.\")\n",
    "\n",
    "flags.DEFINE_float(\n",
    "    \"warmup_proportion\", 0.1,\n",
    "    \"Proportion of training to perform linear learning rate warmup for. \"\n",
    "    \"E.g., 0.1 = 10% of training.\")\n",
    "\n",
    "flags.DEFINE_integer(\"save_checkpoints_steps\", 1000,\n",
    "                     \"How often to save the model checkpoint.\")\n",
    "\n",
    "flags.DEFINE_integer(\"iterations_per_loop\", 1000,\n",
    "                     \"How many steps to make in each estimator call.\")\n",
    "\n",
    "flags.DEFINE_bool(\"use_tpu\", False, \"Whether to use TPU or GPU/CPU.\")\n",
    "\n",
    "tf.flags.DEFINE_string(\n",
    "    \"tpu_name\", None,\n",
    "    \"The Cloud TPU to use for training. This should be either the name \"\n",
    "    \"used when creating the Cloud TPU, or a grpc://ip.address.of.tpu:8470 \"\n",
    "    \"url.\")\n",
    "\n",
    "tf.flags.DEFINE_string(\n",
    "    \"tpu_zone\", None,\n",
    "    \"[Optional] GCE zone where the Cloud TPU is located in. If not \"\n",
    "    \"specified, we will attempt to automatically detect the GCE project from \"\n",
    "    \"metadata.\")\n",
    "\n",
    "tf.flags.DEFINE_string(\n",
    "    \"gcp_project\", None,\n",
    "    \"[Optional] Project name for the Cloud TPU-enabled project. If not \"\n",
    "    \"specified, we will attempt to automatically detect the GCE project from \"\n",
    "    \"metadata.\")\n",
    "\n",
    "tf.flags.DEFINE_string(\"master\", None, \"[Optional] TensorFlow master URL.\")\n",
    "\n",
    "flags.DEFINE_integer(\n",
    "    \"num_tpu_cores\", 8,\n",
    "    \"Only used if `use_tpu` is True. Total number of TPU cores to use.\")\n",
    "\n",
    "# task specific parameter( sentiment analysis)\n",
    "flags.DEFINE_integer(\"num_classes\", 40, \"Total number of labels for sentiment analysis\")\n",
    "flags.DEFINE_integer(\"num_aspects\", 20, \"Total number of aspect\")\n",
    "\n",
    "flags.DEFINE_list(\"aspect_value_list\", [0, 1], \"Values that a aspect can have\")\n",
    "tf.app.flags.DEFINE_string('f', '', 'kernel')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84ce3f0",
   "metadata": {},
   "source": [
    "###### Making Data Ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e153995f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e2f8769b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PaddingInputExample(object):\n",
    "    \"\"\"Fake example so the num input examples is a multiple of the batch size.\n",
    "    When running eval/predict on the TPU, we need to pad the number of examples\n",
    "    to be a multiple of the batch size, because the TPU requires a fixed batch\n",
    "    size. The alternative is to drop the last batch, which is bad because it means\n",
    "    the entire output data won't be generated.\n",
    "    We use this class instead of `None` because treating `None` as padding\n",
    "    battches could cause silent errors.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f408444",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputFeatures(object):\n",
    "\n",
    "    def __init__(self, input_ids, input_mask, segment_ids, label_id, is_real_example=True):\n",
    "        self.input_ids = input_ids\n",
    "        self.input_mask = input_mask\n",
    "        self.segment_ids = segment_ids\n",
    "        self.label_id = label_id\n",
    "        self.is_real_example=is_real_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8500bb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_single_example(ex_index, example, label_list, max_seq_length,tokenizer):\n",
    "    \"\"\"Converts a single `InputExample` into a single `InputFeatures`.\"\"\"\n",
    "\n",
    "    if isinstance(example, PaddingInputExample):\n",
    "        return InputFeatures(\n",
    "            input_ids=[0] * max_seq_length,\n",
    "            input_mask=[0] * max_seq_length,\n",
    "            segment_ids=[0] * max_seq_length,\n",
    "            label_id=0,\n",
    "            is_real_example=False)\n",
    "\n",
    "    label_map = {}\n",
    "    for (i, label) in enumerate(label_list):\n",
    "        label_map[label] = i\n",
    "\n",
    "    tokens_a = tokenizer.tokenize(example.text_a)\n",
    "    tokens_b = None\n",
    "    if example.text_b:\n",
    "        tokens_b = tokenizer.tokenize(example.text_b)\n",
    "\n",
    "    if tokens_b:\n",
    "        # Modifies `tokens_a` and `tokens_b` in place so that the total\n",
    "        # length is less than the specified length.\n",
    "        # Account for [CLS], [SEP], [SEP] with \"- 3\"\n",
    "        _truncate_seq_pair(tokens_a, tokens_b, max_seq_length - 3)\n",
    "    else:\n",
    "        # Account for [CLS] and [SEP] with \"- 2\"\n",
    "        if len(tokens_a) > max_seq_length - 2:\n",
    "            tokens_a = tokens_a[0:(max_seq_length - 2)]\n",
    "\n",
    "    \n",
    "    tokens = []\n",
    "    segment_ids = []\n",
    "    tokens.append(\"[CLS]\")\n",
    "    segment_ids.append(0)\n",
    "    for token in tokens_a:\n",
    "        tokens.append(token)\n",
    "        segment_ids.append(0)\n",
    "    tokens.append(\"[SEP]\")\n",
    "    segment_ids.append(0)\n",
    "\n",
    "    if tokens_b:\n",
    "        for token in tokens_b:\n",
    "            tokens.append(token)\n",
    "            segment_ids.append(1)\n",
    "        tokens.append(\"[SEP]\")\n",
    "        segment_ids.append(1)\n",
    "\n",
    "    input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "    # The mask has 1 for real tokens and 0 for padding tokens. Only real\n",
    "    # tokens are attended to.\n",
    "    input_mask = [1] * len(input_ids)\n",
    "\n",
    "    # Zero-pad up to the sequence length.\n",
    "    while len(input_ids) < max_seq_length:\n",
    "        input_ids.append(0)\n",
    "        input_mask.append(0)\n",
    "        segment_ids.append(0)\n",
    "\n",
    "    assert len(input_ids) == max_seq_length\n",
    "    assert len(input_mask) == max_seq_length\n",
    "    assert len(segment_ids) == max_seq_length\n",
    "    # print(\"label_map:\",label_map,\";length of label_map:\",len(label_map))\n",
    "   # example.label =  example.label.replace(' ', ',')\n",
    "    label_id = None\n",
    "    if \",\" in example.label:  # multiple label\n",
    "        # get list of label\n",
    "        label_id_list = []\n",
    "        label_list = example.label.split(\",\")\n",
    "        for label_ in label_list:\n",
    "            try:\n",
    "                label_id_list.append(label_map[label_])\n",
    "            except:\n",
    "                tf.logging.error(label_)\n",
    "                tf.logging.error(label_map)\n",
    "                exit(1)\n",
    "        label_id = [0 for l in range(len(label_map))]\n",
    "        for j, label_index in enumerate(label_id_list):\n",
    "            label_id[label_index] = 1\n",
    "    else:  # single label\n",
    "        label_id = label_map[example.label]\n",
    "    if ex_index < 5:\n",
    "        tf.logging.info(\"*** Example ***\")\n",
    "        tf.logging.info(\"guid: %s\" % (example.guid))\n",
    "        tf.logging.info(\"tokens: %s\" % \" \".join(\n",
    "            [tokenization.printable_text(x) for x in tokens]))\n",
    "        tf.logging.info(\"input_ids: %s\" % \" \".join([str(x) for x in input_ids]))\n",
    "        tf.logging.info(\"input_mask: %s\" % \" \".join([str(x) for x in input_mask]))\n",
    "        tf.logging.info(\"segment_ids: %s\" % \" \".join([str(x) for x in segment_ids]))\n",
    "        if \",\" in example.label: tf.logging.info(\"label: %s (id_list = %s)\" % (str(example.label),\n",
    "                                                                               str(\n",
    "                                                                                   label_id_list)))  # if label_id is a list, try print multi-hot value: label_id_list\n",
    "        tf.logging.info(\"label: %s (id = %s)\" % (str(example.label), str(label_id)))  # %d\n",
    "\n",
    "    feature = InputFeatures(\n",
    "        input_ids=input_ids,\n",
    "        input_mask=input_mask,\n",
    "        segment_ids=segment_ids,\n",
    "        label_id = label_id,\n",
    "        is_real_example=True)\n",
    "    return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "75186f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_based_convert_examples_to_features(examples, label_list, max_seq_length, tokenizer, output_file):\n",
    "    \"\"\"Convert a set of `InputExample`s to a TFRecord file.\"\"\"\n",
    "\n",
    "    writer = tf.io.TFRecordWriter(output_file)\n",
    "\n",
    "    for (ex_index, example) in enumerate(examples):\n",
    "        if ex_index % 10000 == 0:\n",
    "            tf.logging.info(\"Writing example %d of %d\" % (ex_index, len(examples)))\n",
    "\n",
    "        feature = convert_single_example(ex_index, example, label_list,\n",
    "                                         max_seq_length, tokenizer)\n",
    "\n",
    "        def create_int_feature(values):\n",
    "            f = tf.train.Feature(int64_list=tf.train.Int64List(value=list(values)))\n",
    "            return f\n",
    "\n",
    "        features = collections.OrderedDict()\n",
    "        features[\"input_ids\"] = create_int_feature(feature.input_ids)\n",
    "        features[\"input_mask\"] = create_int_feature(feature.input_mask)\n",
    "        features[\"segment_ids\"] = create_int_feature(feature.segment_ids)\n",
    "\n",
    "        if isinstance(feature.label_id, list):\n",
    "            label_ids = feature.label_id\n",
    "        else:\n",
    "            label_ids = [feature.label_id]\n",
    "        features[\"label_ids\"] = create_int_feature(label_ids)\n",
    "        #label_ids.extend(pad_sequence(label_ids,FLAGS.num_classes))\n",
    "        features[\"is_real_example\"] = create_int_feature(\n",
    "            [int(feature.is_real_example)])\n",
    "        tf_example = tf.train.Example(features=tf.train.Features(feature=features))\n",
    "        writer.write(tf_example.SerializeToString())\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "103dc2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_based_input_fn_builder(input_file, seq_length, is_training,\n",
    "                                drop_remainder):\n",
    "    \"\"\"Creates an `input_fn` closure to be passed to TPUEstimator.\"\"\"\n",
    "    # task specific parameter\n",
    "    name_to_features = {\n",
    "        \"input_ids\": tf.FixedLenFeature([seq_length], tf.int64),\n",
    "        \"input_mask\": tf.FixedLenFeature([seq_length], tf.int64),\n",
    "        \"segment_ids\": tf.FixedLenFeature([seq_length], tf.int64),\n",
    "        \"label_ids\": tf.FixedLenFeature([FLAGS.num_classes], tf.int64),  # ADD TO A FIXED LENGTH\n",
    "        \"is_real_example\": tf.FixedLenFeature([], tf.int64),\n",
    "    }\n",
    "\n",
    "    def _decode_record(record, name_to_features):\n",
    "        \"\"\"Decodes a record to a TensorFlow example.\"\"\"\n",
    "        example = tf.parse_single_example(record, name_to_features)\n",
    "       # label_ids = tf.cast(example['label_ids'], dtype=tf.int32)\n",
    "        for name in list(example.keys()):\n",
    "            t = example[name]\n",
    "            if t.dtype == tf.int64:\n",
    "                t = tf.to_int32(t)\n",
    "            example[name] = t\n",
    "\n",
    "        return example\n",
    "\n",
    "    def input_fn(params):\n",
    "        \"\"\"The actual input function.\"\"\"\n",
    "        batch_size = params[\"batch_size\"]\n",
    "\n",
    "        d = tf.data.TFRecordDataset(input_file)\n",
    "        if is_training:\n",
    "            d = d.repeat()\n",
    "            d = d.shuffle(buffer_size=100)\n",
    "\n",
    "        d = d.apply(\n",
    "            tf.contrib.data.map_and_batch(\n",
    "                lambda record: _decode_record(record, name_to_features),\n",
    "                batch_size=batch_size,\n",
    "                drop_remainder=drop_remainder))\n",
    "\n",
    "        return d\n",
    "\n",
    "    return input_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dad7dd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _truncate_seq_pair(tokens_a, tokens_b, max_length=FLAGS.max_seq_length):\n",
    "    while True:\n",
    "        total_length = len(tokens_a) + len(tokens_b)\n",
    "        if total_length <= max_length:\n",
    "            break\n",
    "        if len(tokens_a) > len(tokens_b):\n",
    "            tokens_a.pop()\n",
    "        else:\n",
    "            tokens_b.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5a2bab54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(bert_config, is_training, input_ids, input_mask, segment_ids,\n",
    "                 labels, num_labels, use_one_hot_embeddings):\n",
    "    model = modeling.BertModel(\n",
    "        config=bert_config,\n",
    "        is_training=is_training,\n",
    "        input_ids=input_ids,\n",
    "        input_mask=input_mask,\n",
    "        token_type_ids=segment_ids,\n",
    "        use_one_hot_embeddings=use_one_hot_embeddings)\n",
    "\n",
    "    output_layer = model.get_pooled_output()\n",
    "\n",
    "    hidden_size = output_layer.shape[-1].value\n",
    "\n",
    "    output_weights = tf.get_variable(\n",
    "        \"output_weights\", [num_labels, hidden_size],\n",
    "        initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "\n",
    "    output_bias = tf.get_variable(\n",
    "        \"output_bias\", [num_labels], initializer=tf.zeros_initializer())\n",
    "\n",
    "    with tf.variable_scope(\"loss\"):\n",
    "        if is_training:\n",
    "            output_layer = tf.nn.dropout(output_layer, keep_prob=0.9)\n",
    "\n",
    "        logits = tf.matmul(output_layer, output_weights, transpose_b=True)\n",
    "        logits = tf.nn.bias_add(logits, output_bias)\n",
    "\n",
    "        probabilities = tf.nn.sigmoid(logits)\n",
    "        labels = tf.cast(labels, tf.float32)\n",
    "        per_example_loss = tf.nn.sigmoid_cross_entropy_with_logits(labels=labels, logits=logits)\n",
    "        loss = tf.reduce_mean(per_example_loss)\n",
    "\n",
    "        return (loss, per_example_loss, logits, probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3ddf4d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn_builder(bert_config, num_labels, init_checkpoint, learning_rate,\n",
    "                     num_train_steps, num_warmup_steps, use_tpu,\n",
    "                     use_one_hot_embeddings):\n",
    "    \"\"\"Returns `model_fn` closure for TPUEstimator.\"\"\"\n",
    "\n",
    "    def model_fn(features, labels, mode, params):  # pylint: disable=unused-argument\n",
    "        \"\"\"The `model_fn` for TPUEstimator.\"\"\"\n",
    "\n",
    "        tf.logging.info(\"*** Features ***\")\n",
    "        for name in sorted(features.keys()):\n",
    "            tf.logging.info(\"  name = %s, shape = %s\" % (name, features[name].shape))\n",
    "\n",
    "        input_ids = features[\"input_ids\"]\n",
    "        input_mask = features[\"input_mask\"]\n",
    "        segment_ids = features[\"segment_ids\"]\n",
    "        label_ids = features[\"label_ids\"]\n",
    "        is_real_example = None\n",
    "        if \"is_real_example\" in features:\n",
    "            is_real_example = tf.cast(features[\"is_real_example\"], dtype=tf.float32)\n",
    "        else:\n",
    "            is_real_example = tf.ones(tf.shape(label_ids), dtype=tf.float32)\n",
    "\n",
    "        is_training = (mode == tf.estimator.ModeKeys.TRAIN)\n",
    "\n",
    "        (total_loss, per_example_loss, logits, probabilities) = create_model(\n",
    "            bert_config, is_training, input_ids, input_mask, segment_ids, label_ids,\n",
    "            num_labels, use_one_hot_embeddings)\n",
    "\n",
    "        tvars = tf.trainable_variables()\n",
    "        initialized_variable_names = {}\n",
    "        scaffold_fn = None\n",
    "        if init_checkpoint:\n",
    "            (assignment_map, initialized_variable_names\n",
    "             ) = modeling.get_assignment_map_from_checkpoint(tvars, init_checkpoint)\n",
    "            if use_tpu:\n",
    "\n",
    "                def tpu_scaffold():\n",
    "                    tf.train.init_from_checkpoint(init_checkpoint, assignment_map)\n",
    "                    return tf.train.Scaffold()\n",
    "\n",
    "                scaffold_fn = tpu_scaffold\n",
    "            else:\n",
    "                tf.train.init_from_checkpoint(init_checkpoint, assignment_map)\n",
    "\n",
    "        tf.logging.info(\"**** Trainable Variables ****\")\n",
    "        for var in tvars:\n",
    "            init_string = \"\"\n",
    "            if var.name in initialized_variable_names:\n",
    "                init_string = \", *INIT_FROM_CKPT*\"\n",
    "            tf.logging.info(\"  name = %s, shape = %s%s\", var.name, var.shape,\n",
    "                            init_string)\n",
    "\n",
    "        output_spec = None\n",
    "        if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "\n",
    "            train_op = optimization.create_optimizer(\n",
    "                total_loss, learning_rate, num_train_steps, num_warmup_steps, use_tpu)\n",
    "\n",
    "            output_spec = tf.contrib.tpu.TPUEstimatorSpec(\n",
    "                mode=mode,\n",
    "                loss=total_loss,\n",
    "                train_op=train_op,\n",
    "                scaffold_fn=scaffold_fn)\n",
    "        elif mode == tf.estimator.ModeKeys.EVAL:\n",
    "\n",
    "            def metric_fn(per_example_loss, label_ids,probabilities, is_real_example):\n",
    "                # print(\"###metric_fn.logits:\",logits.shape) # (?,80)\n",
    "                # predictions = tf.argmax(logits, axis=-1, output_type=tf.int32)\n",
    "                # print(\"###metric_fn.label_ids:\",label_ids.shape,\";predictions:\",predictions.shape) # label_ids: (?,80);predictions:(?,)\n",
    "                logits_split = tf.split(probabilities, FLAGS.num_aspects,\n",
    "                                        axis=-1)  # a list. length is num_aspects\n",
    "                label_ids_split = tf.split(label_ids, FLAGS.num_aspects,\n",
    "                                           axis=-1)  # a list. length is num_aspects\n",
    "                accuracy = tf.constant(0.0, dtype=tf.float64)\n",
    "\n",
    "                for j, logits in enumerate(logits_split):  #\n",
    "                    #  accuracy = tf.metrics.accuracy(label_ids, predictions)\n",
    "\n",
    "                    predictions = tf.argmax(logits, axis=-1,\n",
    "                                            output_type=tf.int32)  # should be [batch_size,]\n",
    "                    label_id_ = tf.cast(tf.argmax(label_ids_split[j], axis=-1), dtype=tf.int32)\n",
    "                    tf.logging.debug(\"label_ids_split[j] = %s; predictions = %s; label_id_ = %s\" %\n",
    "                                     (label_ids_split[j], predictions, label_id_))\n",
    "                    current_accuracy, update_op_accuracy = tf.metrics.accuracy(\n",
    "                                    labels=label_id_, predictions= predictions, weights=is_real_example)\n",
    "                    accuracy += tf.cast(current_accuracy, dtype=tf.float64)\n",
    "                #accuracy = accuracy / tf.constant(FLAGS.num_aspects, dtype=tf.float64)\n",
    "                loss = tf.metrics.mean(per_example_loss)\n",
    "                return {\n",
    "                    \"eval_accuracy\": (accuracy, update_op_accuracy),\n",
    "                    \"eval_loss\": loss,\n",
    "                }\n",
    "\n",
    "            eval_metrics = (metric_fn,\n",
    "                            [per_example_loss, label_ids,probabilities, is_real_example])\n",
    "            output_spec = tf.contrib.tpu.TPUEstimatorSpec(\n",
    "                mode=mode,\n",
    "                loss=total_loss,\n",
    "                eval_metrics=eval_metrics,\n",
    "                scaffold_fn=scaffold_fn)\n",
    "        else:\n",
    "            logits_split = tf.split(probabilities, FLAGS.num_aspects,\n",
    "                                        axis=-1)  # a list. length is num_aspects\n",
    "            label_ids_split = tf.split(label_ids, FLAGS.num_aspects,\n",
    "                                           axis=-1)  # a list. length is num_aspects\n",
    "            accuracy = tf.constant(0.0, dtype=tf.float64)\n",
    "\n",
    "            for j, logits in enumerate(logits_split):  \n",
    "                predictions = tf.argmax(logits, axis=-1,\n",
    "                                            output_type=tf.int32)  # should be [batch_size,]\n",
    "                label_id_ = tf.cast(tf.argmax(label_ids_split[j], axis=-1), dtype=tf.int32)\n",
    "                tf.logging.debug(\"label_ids_split[j] = %s; predictions = %s; label_id_ = %s\" %\n",
    "                                     (label_ids_split[j], predictions, label_id_))\n",
    "                current_accuracy, update_op_accuracy = tf.metrics.accuracy(\n",
    "                                    labels=label_id_, predictions= predictions, weights=is_real_example)\n",
    "                accuracy += tf.cast(current_accuracy, dtype=tf.float64)\n",
    "            \n",
    "            output_spec = tf.contrib.tpu.TPUEstimatorSpec(\n",
    "                mode=mode,\n",
    "                predictions={\"probabilities\": probabilities,\n",
    "                            \"label_ids\":label_ids\n",
    "                            },\n",
    "                scaffold_fn=scaffold_fn)\n",
    "        return output_spec\n",
    "\n",
    "    return model_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f323cd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_fn_builder(features, seq_length, is_training, drop_remainder):\n",
    "    \"\"\"Creates an `input_fn` closure to be passed to TPUEstimator.\"\"\"\n",
    "\n",
    "    all_input_ids = []\n",
    "    all_input_mask = []\n",
    "    all_segment_ids = []\n",
    "    all_label_ids = []\n",
    "\n",
    "    for feature in features:\n",
    "        all_input_ids.append(feature.input_ids)\n",
    "        all_input_mask.append(feature.input_mask)\n",
    "        all_segment_ids.append(feature.segment_ids)\n",
    "        all_label_ids.append(feature.label_id)\n",
    "\n",
    "    def input_fn(params):\n",
    "        \"\"\"The actual input function.\"\"\"\n",
    "        batch_size = params[\"batch_size\"]\n",
    "\n",
    "        num_examples = len(features)\n",
    "        d = tf.data.Dataset.from_tensor_slices({\n",
    "            \"input_ids\":\n",
    "                tf.constant(\n",
    "                    all_input_ids, shape=[num_examples, seq_length],\n",
    "                    dtype=tf.int32),\n",
    "            \"input_mask\":\n",
    "                tf.constant(\n",
    "                    all_input_mask,\n",
    "                    shape=[num_examples, seq_length],\n",
    "                    dtype=tf.int32),\n",
    "            \"segment_ids\":\n",
    "                tf.constant(\n",
    "                    all_segment_ids,\n",
    "                    shape=[num_examples, seq_length],\n",
    "                    dtype=tf.int32),\n",
    "            \"label_ids\":\n",
    "                tf.constant(all_label_ids, shape=[num_examples], dtype=tf.int32),\n",
    "        })\n",
    "\n",
    "        if is_training:\n",
    "            d = d.repeat()\n",
    "            d = d.shuffle(buffer_size=100)\n",
    "\n",
    "        d = d.batch(batch_size=batch_size, drop_remainder=drop_remainder)\n",
    "        return d\n",
    "    return input_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "41d8b548",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_examples_to_features(examples, label_list, max_seq_length=FLAGS.max_seq_length,\n",
    "                                 tokenizer= tokenization.FullTokenizer(vocab_file=FLAGS.vocab_file, do_lower_case=FLAGS.do_lower_case)):\n",
    "    \"\"\"Convert a set of `InputExample`s to a list of `InputFeatures`.\"\"\"\n",
    "\n",
    "    features = []\n",
    "    for (ex_index, example) in enumerate(examples):\n",
    "        if ex_index % 10000 == 0:\n",
    "            tf.logging.info(\"Writing example %d of %d\" % (ex_index, len(examples)))\n",
    "\n",
    "        feature = convert_single_example(ex_index, example, label_list,\n",
    "                                         max_seq_length, tokenizer)\n",
    "\n",
    "        features.append(feature)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9ddadd",
   "metadata": {},
   "source": [
    "### Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bf384953",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\u1111995\\AppData\\Local\\Temp/ipykernel_17112/9565544.py:1: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tf.compat.v1.logging.set_verbosity(tf.logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "525df0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenization.validate_case_matches_checkpoint(FLAGS.do_lower_case,\n",
    "                                                  FLAGS.init_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "794a790f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_config = modeling.BertConfig.from_json_file(FLAGS.bert_config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "97643a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tokenization.FullTokenizer(\n",
    "        vocab_file=FLAGS.vocab_file, do_lower_case=FLAGS.do_lower_case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "93b3cddc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this',\n",
       " 'here',\n",
       " \"'\",\n",
       " 's',\n",
       " 'an',\n",
       " 'example',\n",
       " 'of',\n",
       " 'using',\n",
       " 'the',\n",
       " 'bert',\n",
       " 'token',\n",
       " '##izer']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize(\"This here's an example of using the BERT tokenizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "826df793",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = r\"C:\\Users\\u1111995\\Desktop\\project 2\\Output8\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3a6ac66a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\u1111995\\AppData\\Local\\Temp/ipykernel_17112/1964057354.py:1: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tf.gfile.MakeDirs(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "84f00577",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Codie_label_path = \"C:/Users/u1111995/Desktop/project 2/Codie_Data/Data\"\n",
    "#Labels_df = pd.read_csv((Codie_label_path + \"/MapFile.txt\"), sep=\"\\t\")\n",
    "#df = pd.DataFrame(Labels_df['Label'])\n",
    "#Labels_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e052077f",
   "metadata": {},
   "outputs": [],
   "source": [
    " def get_labels():\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        label_list = []\n",
    "        # num_aspect=FLAGS.num_aspects\n",
    "        aspect_value_list = FLAGS.aspect_value_list  # [-2,-1,0,1]\n",
    "        for i in range(FLAGS.num_aspects):\n",
    "            for value in aspect_value_list:\n",
    "                label_list.append(str(i) + \"_\" + str(value))\n",
    "        return label_list  # [ {'0_-2': 0, '0_-1': 1, '0_0': 2, '0_1': 3,....'19_-2': 76, '19_-1': 77, '19_0': 78, '19_1': 79}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e2a84268",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0_0',\n",
       " '0_1',\n",
       " '1_0',\n",
       " '1_1',\n",
       " '2_0',\n",
       " '2_1',\n",
       " '3_0',\n",
       " '3_1',\n",
       " '4_0',\n",
       " '4_1',\n",
       " '5_0',\n",
       " '5_1',\n",
       " '6_0',\n",
       " '6_1',\n",
       " '7_0',\n",
       " '7_1',\n",
       " '8_0',\n",
       " '8_1',\n",
       " '9_0',\n",
       " '9_1',\n",
       " '10_0',\n",
       " '10_1',\n",
       " '11_0',\n",
       " '11_1',\n",
       " '12_0',\n",
       " '12_1',\n",
       " '13_0',\n",
       " '13_1',\n",
       " '14_0',\n",
       " '14_1',\n",
       " '15_0',\n",
       " '15_1',\n",
       " '16_0',\n",
       " '16_1',\n",
       " '17_0',\n",
       " '17_1',\n",
       " '18_0',\n",
       " '18_1',\n",
       " '19_0',\n",
       " '19_1']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_list = get_labels()\n",
    "label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e9b66b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tpu_cluster_resolver = None\n",
    "if FLAGS.use_tpu and FLAGS.tpu_name:\n",
    "    tpu_cluster_resolver = tf.contrib.cluster_resolver.TPUClusterResolver(\n",
    "            FLAGS.tpu_name, zone=FLAGS.tpu_zone, project=FLAGS.gcp_project)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1d5fc3ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "is_per_host = tf.contrib.tpu.InputPipelineConfig.PER_HOST_V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "46bba9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_config = tf.contrib.tpu.RunConfig(\n",
    "        cluster=tpu_cluster_resolver,\n",
    "        master=FLAGS.master,\n",
    "        model_dir=output_dir,\n",
    "        save_checkpoints_steps=FLAGS.save_checkpoints_steps,\n",
    "        tpu_config=tf.contrib.tpu.TPUConfig(\n",
    "            iterations_per_loop=FLAGS.iterations_per_loop,\n",
    "            num_shards=FLAGS.num_tpu_cores,\n",
    "            per_host_input_for_training=is_per_host))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216fd7c9",
   "metadata": {},
   "source": [
    "### TrainExamples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "980f98cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = r\"C:\\Users\\u1111995\\Desktop\\project 2\\Codie_Data\\Data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4fcecef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'codietrain16.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4a185d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "gk = pd.read_csv(os.path.join(data_dir, \"codietrain16.tsv\"),sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d773be6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputExample(object):\n",
    "    \"\"\"A single training/test example for simple sequence classification.\"\"\"\n",
    "\n",
    "    def __init__(self, guid, text_a, label, text_b=None):\n",
    "        self.guid = guid\n",
    "        self.text_a = text_a\n",
    "        self.text_b = text_b\n",
    "        self.label = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "89db39dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_examples(gk, set_type):\n",
    "    examples = []\n",
    "    for i in range(len(gk)):\n",
    "      #  if i == 0:\n",
    "      #      continue\n",
    "        guid = \"%s-%s\" % (set_type, i)\n",
    "        label = tokenization.convert_to_unicode(gk.label[i])\n",
    "        text_a = tokenization.convert_to_unicode(gk.notes[i])\n",
    "        examples.append(\n",
    "                InputExample(guid=guid, text_a=text_a,label=label,text_b=None))\n",
    "    return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f3f7493b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_examples(data_dir):\n",
    "    return _create_examples(gk, \"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "50aa6e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_examples = None\n",
    "num_train_steps = None\n",
    "num_warmup_steps = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3bb3455e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0_0,1_0,2_0,3_0,4_0,5_0,6_0,7_0,8_0,9_0,10_0,11_0,12_0,13_1,14_0,15_0,16_0,17_0,18_0,19_0'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_examples = get_train_examples(data_dir)\n",
    "train_examples[0].label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c7934b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train_steps = int(len(train_examples) / FLAGS.train_batch_size * FLAGS.num_train_epochs)\n",
    "num_warmup_steps = int(num_train_steps * FLAGS.warmup_proportion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "83cb6069",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "225"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_train_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e5f5be96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_warmup_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6f51123f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3ea6b3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fn = model_fn_builder(\n",
    "        bert_config=bert_config,\n",
    "        num_labels=len(label_list),\n",
    "        init_checkpoint=FLAGS.init_checkpoint,\n",
    "        learning_rate=FLAGS.learning_rate,\n",
    "        num_train_steps=num_train_steps,\n",
    "        num_warmup_steps=num_warmup_steps,\n",
    "        use_tpu=FLAGS.use_tpu,\n",
    "        use_one_hot_embeddings=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9c2b105d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x000001490F2A6A68>) includes params argument, but params are not passed to Estimator.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\u1111995\\\\Desktop\\\\project 2\\\\Output8', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 1000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x00000149101BEE48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=1000, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1), '_cluster': None}\n",
      "INFO:tensorflow:_TPUContext: eval_on_tpu True\n",
      "WARNING:tensorflow:eval_on_tpu ignored because use_tpu is False.\n"
     ]
    }
   ],
   "source": [
    "estimator = tf.contrib.tpu.TPUEstimator(\n",
    "        use_tpu=FLAGS.use_tpu,\n",
    "        model_fn=model_fn,\n",
    "        config=run_config,\n",
    "        train_batch_size=FLAGS.train_batch_size,\n",
    "        eval_batch_size=FLAGS.eval_batch_size,\n",
    "        predict_batch_size=FLAGS.predict_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d8184b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\u1111995\\AppData\\Local\\Temp/ipykernel_17112/457356033.py:8: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
      "\n",
      "INFO:tensorflow:Writing example 0 of 300\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:guid: train-0\n",
      "INFO:tensorflow:tokens: [CLS] a 46 - year - old male , with no relevant medical history , non ##smo ##ker . she underwent fixed rehabilitation on a single implant ( it ##i ##® sl ##a ) . st ##ra ##uman ##n . wal ##der ##burg - switzerland ) placed in zone 3 . 6 . six months after cement ##ing the crown , the patient came to control with no associated symptoms . clinical examination revealed slight red ##ness of the mu ##cos ##a adjacent to the implant and a 6 mm deep per ##i - implant pocket with mild bleeding on probing . the role of joint showed premature contact with pro ##st ##hetic crown . pan ##ora ##mic radio ##graphy showed a radio ##lu ##cent area in the marginal bone at 3 . 6 . the pro ##st ##hetic crown was o ##cc ##lus ##ally carved . subsequently , a mu ##cope ##rit ##ic flap was raised from 3 . 5 to 3 . 7 , a marginal flap of fi ##bro ##us tissue occupying a per ##i - implant bone defect at 3 . 6 . the path ##ological tissue was removed with plastic cure ##ttes and sent for ana ##tom ##opa ##th ##ological study . the implant surface was tape ##red with 0 . 2 % ch ##lor ##he ##xi ##dine gel for 2 minutes and irrigation with saline . the flap was extended to access a ling ##ual man ##di ##bular tor ##us in ip ##sil ##ater ##al prem ##olar area , which was extracted and articulated to serve as a self - injection . the flap was rep ##osition ##ed and su ##ture ##d with 3 . 0 silk . the patient was re - instructed in oral hygiene , ib ##up ##ro ##fen 600 mg every 8 hr ##s x 4 days and eyed ##rop ##s with ch ##lor ##he ##xi ##dine dig ##lu ##cona ##te 0 . 12 % twice a day x 2 weeks . his ##top ##ath ##ological analysis showed an ep ##ith ##elial connect ##ive tissue with abundant l ##ym ##ph ##op ##las ##mac ##ytic and ju ##xt ##ae ##pit ##hel ##ial infiltrate . dense fi ##bro ##con ##ne ##ctive tissue with few inflammatory cells was observed under the superficial area . twelve months after the surgical treatment , a radio ##graph showed marginal bone recovery and a normal clinical appearance , with no symptoms . [SEP]\n",
      "INFO:tensorflow:input_ids: 101 1037 4805 1011 2095 1011 2214 3287 1010 2007 2053 7882 2966 2381 1010 2512 25855 5484 1012 2016 9601 4964 11252 2006 1037 2309 27159 1006 2009 2072 29656 22889 2050 1007 1012 2358 2527 19042 2078 1012 24547 4063 4645 1011 5288 1007 2872 1999 4224 1017 1012 1020 1012 2416 2706 2044 11297 2075 1996 4410 1010 1996 5776 2234 2000 2491 2007 2053 3378 8030 1012 6612 7749 3936 7263 2417 2791 1997 1996 14163 13186 2050 5516 2000 1996 27159 1998 1037 1020 3461 2784 2566 2072 1011 27159 4979 2007 10256 9524 2006 28664 1012 1996 2535 1997 4101 3662 21371 3967 2007 4013 3367 20086 4410 1012 6090 6525 7712 2557 12565 3662 1037 2557 7630 13013 2181 1999 1996 14785 5923 2012 1017 1012 1020 1012 1996 4013 3367 20086 4410 2001 1051 9468 7393 3973 7844 1012 3525 1010 1037 14163 16186 14778 2594 20916 2001 2992 2013 1017 1012 1019 2000 1017 1012 1021 1010 1037 14785 20916 1997 10882 12618 2271 8153 13992 1037 2566 2072 1011 27159 5923 21262 2012 1017 1012 1020 1012 1996 4130 10091 8153 2001 3718 2007 6081 9526 14581 1998 2741 2005 9617 20389 29477 2705 10091 2817 1012 1996 27159 3302 2001 6823 5596 2007 1014 1012 1016 1003 10381 10626 5369 9048 10672 21500 2005 1016 2781 1998 12442 2007 28413 1012 1996 20916 2001 3668 2000 3229 1037 17002 8787 2158 4305 28808 17153 2271 1999 12997 27572 24932 2389 26563 19478 2181 1010 2029 2001 15901 1998 20742 2000 3710 2004 1037 2969 1011 13341 1012 1996 20916 2001 16360 19234 2098 1998 10514 11244 2094 2007 1017 1012 1014 6953 1012 1996 5776 2001 2128 1011 10290 1999 8700 19548 1010 21307 6279 3217 18940 5174 11460 2296 1022 17850 2015 1060 1018 2420 1998 7168 18981 2015 2007 10381 10626 5369 9048 10672 10667 7630 24366 2618 1014 1012 2260 1003 3807 1037 2154 1060 1016 3134 1012 2010 14399 8988 10091 4106 3662 2019 4958 8939 24587 7532 3512 8153 2007 12990 1048 24335 8458 7361 8523 22911 21252 1998 18414 18413 6679 23270 16001 4818 29543 1012 9742 10882 12618 8663 2638 15277 8153 2007 2261 20187 4442 2001 5159 2104 1996 23105 2181 1012 4376 2706 2044 1996 11707 3949 1010 1037 2557 14413 3662 14785 5923 7233 1998 1037 3671 6612 3311 1010 2007 2053 8030 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:label: 0_0,1_0,2_0,3_0,4_0,5_0,6_0,7_0,8_0,9_0,10_0,11_0,12_0,13_1,14_0,15_0,16_0,17_0,18_0,19_0 (id_list = [0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 27, 28, 30, 32, 34, 36, 38])\n",
      "INFO:tensorflow:label: 0_0,1_0,2_0,3_0,4_0,5_0,6_0,7_0,8_0,9_0,10_0,11_0,12_0,13_1,14_0,15_0,16_0,17_0,18_0,19_0 (id = [1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0])\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:guid: train-1\n",
      "INFO:tensorflow:tokens: [CLS] a 57 - year - old male . she had a history of right ne ##ph ##re ##ct ##omy for transitional cell car ##cino ##ma in 1991 and radical cy ##sto ##pro ##sta ##tec ##tom ##y with brick ##er - type ur ##ina ##ry diversion in 1995 ( pt ##is no mo , performed due to bc ##g car ##cino ##ma in situ ) . he came to our consultation to assess the conversion of his ur ##ina ##ry diversion to the st ##oma presentation and to note that his life was very limited by the external self - ad ##hesive device . an abdominal cat scan was requested as a staging study , without signs of tumor activity . her baseline cr ##ea ##tin ##ine was 1 . 5 mg / dl . an ex ##pl ##ora ##tory lap ##aro ##sco ##py was performed in may 2003 , with complete di ##sse ##ction of the pe ##lvis , identifying the ur ##eth ##ral stump with a ben ##ich . the ur ##eth ##ral stump was res ##ect ##ed and an intra - operative bio ##psy ruled out tumor ##al lesions . the neo ##bla ##dder ( stud ##er ) was constructed after exterior ##izing 45 cm of terminal ile ##um through the st ##oma or ##ifice . ur ##eth ##ral - neo ##bla ##dder ana ##sto ##mos ##is was performed lap ##aro ##scopic ##ally . the total surgical time was 480 minutes , with an estimated blood loss of 100 cc . the patient was discharged on the sixth post ##oper ##ative day without complications . 1 . the evolution since then months has been favorable , without evidence of metabolic alterations or signs of rec ##ur ##rence of the basal disease . [SEP]\n",
      "INFO:tensorflow:input_ids: 101 1037 5401 1011 2095 1011 2214 3287 1012 2016 2018 1037 2381 1997 2157 11265 8458 2890 6593 16940 2005 17459 3526 2482 21081 2863 1999 2889 1998 7490 22330 16033 21572 9153 26557 20389 2100 2007 5318 2121 1011 2828 24471 3981 2854 20150 1999 2786 1006 13866 2483 2053 9587 1010 2864 2349 2000 4647 2290 2482 21081 2863 1999 26179 1007 1012 2002 2234 2000 2256 16053 2000 14358 1996 7584 1997 2010 24471 3981 2854 20150 2000 1996 2358 9626 8312 1998 2000 3602 2008 2010 2166 2001 2200 3132 2011 1996 6327 2969 1011 4748 21579 5080 1012 2019 21419 4937 13594 2001 7303 2004 1037 15308 2817 1010 2302 5751 1997 13656 4023 1012 2014 26163 13675 5243 7629 3170 2001 1015 1012 1019 11460 1013 21469 1012 2019 4654 24759 6525 7062 5001 10464 9363 7685 2001 2864 1999 2089 2494 1010 2007 3143 4487 11393 7542 1997 1996 21877 28530 1010 12151 1996 24471 11031 7941 22475 2007 1037 3841 7033 1012 1996 24471 11031 7941 22475 2001 24501 22471 2098 1998 2019 26721 1011 12160 16012 18075 5451 2041 13656 2389 22520 1012 1996 9253 28522 20791 1006 16054 2121 1007 2001 3833 2044 8829 6026 3429 4642 1997 5536 17869 2819 2083 1996 2358 9626 2030 23664 1012 24471 11031 7941 1011 9253 28522 20791 9617 16033 15530 2483 2001 2864 5001 10464 24895 3973 1012 1996 2561 11707 2051 2001 17295 2781 1010 2007 2019 4358 2668 3279 1997 2531 10507 1012 1996 5776 2001 14374 2006 1996 4369 2695 25918 8082 2154 2302 12763 1012 1015 1012 1996 6622 2144 2059 2706 2038 2042 11119 1010 2302 3350 1997 21453 16705 2030 5751 1997 28667 3126 24413 1997 1996 15191 4295 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:label: 0_0,1_0,2_0,3_0,4_0,5_0,6_0,7_0,8_0,9_0,10_0,11_0,12_0,13_0,14_0,15_0,16_1,17_1,18_0,19_0 (id_list = [0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 33, 35, 36, 38])\n",
      "INFO:tensorflow:label: 0_0,1_0,2_0,3_0,4_0,5_0,6_0,7_0,8_0,9_0,10_0,11_0,12_0,13_0,14_0,15_0,16_1,17_1,18_0,19_0 (id = [1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0])\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:guid: train-2\n",
      "INFO:tensorflow:tokens: [CLS] a 25 - year - old woman came to the nutrition service for monitoring her nutritional status ; seven months before she had been diagnosed with ul ##cera ##tive coli ##tis ( uc ) , and during this period she had received treatment with oral co ##rti ##cos ##ter ##oids 1 . 5 mg descending iv methyl ##pre ##d ##ni she complained of art ##hra ##l ##gia ##s in both knees , and on physical examination she presented pain at posterior rotation in the two fe ##moral heads , more evident on the right side , hip that also presented limited internal rotation ; the left knee showed reduced movement no markers of auto ##im ##mun ##ity were detected in the analyses performed , and plasma concentrations of calcium , phosphorus and vitamin d were within the range of nor ##nia ##lity . bone den ##sit ##ome ##try ( b ##md ) showed os ##te ##op ##oro ##sis in the lu ##mba ##r spine ( t score - 3 . 1 ) and os ##te ##os ##yn ##thesis in the fe ##moral neck ( t score - 1 . 5 ) . plain radio ##graphs showed data suggest ##ive of grade ii na in both fe ##moral heads , more evident on the right side ; on the knees an os ##te ##och ##ond ##ral les ##ion on the left internal fe ##moral con ##dy ##le was observed . magnetic resonance imaging confirmed nec ##rosis lesions in both fe ##moral heads and both knees , both on the ti ##bial and fe ##moral sides . in the following mri , performed only 3 months later , there was evidence of left hip sinking . 1 . the patient was treated with ale ##nda ##te and calcium and vitamin d supplements due to her os ##te ##op ##oro ##sis , co ##rti ##co ##ids were suspended and the affected weight bearing was advised . [SEP]\n",
      "INFO:tensorflow:input_ids: 101 1037 2423 1011 2095 1011 2214 2450 2234 2000 1996 14266 2326 2005 8822 2014 28268 3570 1025 2698 2706 2077 2016 2018 2042 11441 2007 17359 19357 6024 27441 7315 1006 15384 1007 1010 1998 2076 2023 2558 2016 2018 2363 3949 2007 8700 2522 28228 13186 3334 17086 1015 1012 1019 11460 15127 4921 25003 28139 2094 3490 2016 10865 1997 2396 13492 2140 10440 2015 1999 2119 5042 1010 1998 2006 3558 7749 2016 3591 3255 2012 15219 9963 1999 1996 2048 10768 22049 4641 1010 2062 10358 2006 1996 2157 2217 1010 5099 2008 2036 3591 3132 4722 9963 1025 1996 2187 6181 3662 4359 2929 2053 16387 1997 8285 5714 23041 3012 2020 11156 1999 1996 16478 2864 1010 1998 12123 14061 1997 13853 1010 25473 1998 17663 1040 2020 2306 1996 2846 1997 4496 6200 18605 1012 5923 7939 28032 8462 11129 1006 1038 26876 1007 3662 9808 2618 7361 14604 6190 1999 1996 11320 11201 2099 8560 1006 1056 3556 1011 1017 1012 1015 1007 1998 9808 2618 2891 6038 25078 1999 1996 10768 22049 3300 1006 1056 3556 1011 1015 1012 1019 1007 1012 5810 2557 27341 3662 2951 6592 3512 1997 3694 2462 6583 1999 2119 10768 22049 4641 1010 2062 10358 2006 1996 2157 2217 1025 2006 1996 5042 2019 9808 2618 11663 15422 7941 4649 3258 2006 1996 2187 4722 10768 22049 9530 5149 2571 2001 5159 1012 8060 17011 12126 4484 26785 29166 22520 1999 2119 10768 22049 4641 1998 2119 5042 1010 2119 2006 1996 14841 21102 1998 10768 22049 3903 1012 1999 1996 2206 27011 1010 2864 2069 1017 2706 2101 1010 2045 2001 3350 1997 2187 5099 10186 1012 1015 1012 1996 5776 2001 5845 2007 15669 8943 2618 1998 13853 1998 17663 1040 25654 2349 2000 2014 9808 2618 7361 14604 6190 1010 2522 28228 3597 9821 2020 6731 1998 1996 5360 3635 7682 2001 9449 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:label: 0_0,1_0,2_0,3_1,4_0,5_1,6_0,7_1,8_0,9_0,10_0,11_0,12_0,13_0,14_0,15_0,16_1,17_0,18_0,19_0 (id_list = [0, 2, 4, 7, 8, 11, 12, 15, 16, 18, 20, 22, 24, 26, 28, 30, 33, 34, 36, 38])\n",
      "INFO:tensorflow:label: 0_0,1_0,2_0,3_1,4_0,5_1,6_0,7_1,8_0,9_0,10_0,11_0,12_0,13_0,14_0,15_0,16_1,17_0,18_0,19_0 (id = [1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0])\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:guid: train-3\n",
      "INFO:tensorflow:tokens: [CLS] a 32 - year - old female patient was referred to the pain unit for consultation at the out ##patient clinic due to pain secondary to her ##pet ##ic affection of the op ##ht ##hal ##mic branch of tram ##ado ##l ( 50 / 8 ##h , left ) . its ant ##ece ##dents include episodes of rec ##urrent uv ##eit ##is and uv ##eit ##is that have been labelled as her ##pet ##ic . in the first consultation ( 2001 ) , the patient complained of left eye pain of about 3 months of evolution , with par ##ox ##ys ##mal episodes that increased with certain stimuli such as wind , cold or dry eye . physical examination showed no neurological deficit ##s . pain is rated by the patient with a maximum visual analog scale ( va ##s ) score of 7 - 8 ( during par ##ox ##ys ##ms ) and a minimum of 2 . the diagnosis was post ##her ##pet ##ic neural ##gia of the left cr ##anial nerve branch . treatment with ga ##ba ##pen ##tin and tram ##ado ##l is started in progressive doses , without achieving good pain control and development of side effects in the form of vomiting and dr ##ows ##iness . a series of drug rotation ##s ( ami ##trip ##ty ##line , tomato ) were performed at different doses that did not produce any improvement in pain or adverse manifestation ##s . after patient acceptance , treatment with low frequency electro ##ac ##up ##un ##cture ( ea ) was started ( 2 - 4 hz / s ) , the intensity used was that accepted by the patient as to ##ler ##able . it was applied in fort ##night ##ly sessions of 30 minutes duration . the chosen points were : yin ##tai , bilateral tai ##yang , 18 bilateral id , 4 bilateral i ##g , 3 bilateral h , initially combined with ga ##ba ##pen ##tin ( 300 mg / 12 h ) . 1 . after 6 sessions of treatment , the patient reported better anal ##ges ##ic control and better tolerance to drugs , reason why ga ##ba ##pen ##tin was increased ( 900 mg ) and par ##ox ##ys ##mal administration of tram ##ado ##l ( 25 mg every 6 - 8 hours ) . ae sessions were held weekly . this was followed by better anal ##ges ##ic quality , but vomiting . it was decided to disco ##nti ##nu ##e tram ##ado ##l and gradually increase ga ##ba ##pen ##tin during 2 months ( 2 , 400 mg / 24 h ) . with this new therapeutic plan a pat ##ula ##tine control of par ##ox ##ys ##mal crises was obtained , both in intensity , frequency and duration . after 3 months of clinical stability , the patient barely complained of continuous pain , par ##ox ##ys ##mal crises had decreased in frequency and intensity , and had better tolerance to sleep ##iness . ga ##ba ##pen ##tin was progressively [SEP]\n",
      "INFO:tensorflow:input_ids: 101 1037 3590 1011 2095 1011 2214 2931 5776 2001 3615 2000 1996 3255 3131 2005 16053 2012 1996 2041 24343 9349 2349 2000 3255 3905 2000 2014 22327 2594 12242 1997 1996 6728 11039 8865 7712 3589 1997 12517 9365 2140 1006 2753 1013 1022 2232 1010 2187 1007 1012 2049 14405 26005 28986 2421 4178 1997 28667 29264 23068 20175 2483 1998 23068 20175 2483 2008 2031 2042 18251 2004 2014 22327 2594 1012 1999 1996 2034 16053 1006 2541 1007 1010 1996 5776 10865 1997 2187 3239 3255 1997 2055 1017 2706 1997 6622 1010 2007 11968 11636 7274 9067 4178 2008 3445 2007 3056 22239 2107 2004 3612 1010 3147 2030 4318 3239 1012 3558 7749 3662 2053 23130 15074 2015 1012 3255 2003 6758 2011 1996 5776 2007 1037 4555 5107 11698 4094 1006 12436 2015 1007 3556 1997 1021 1011 1022 1006 2076 11968 11636 7274 5244 1007 1998 1037 6263 1997 1016 1012 1996 11616 2001 2695 5886 22327 2594 15756 10440 1997 1996 2187 13675 27532 9113 3589 1012 3949 2007 11721 3676 11837 7629 1998 12517 9365 2140 2003 2318 1999 6555 21656 1010 2302 10910 2204 3255 2491 1998 2458 1997 2217 3896 1999 1996 2433 1997 24780 1998 2852 15568 9961 1012 1037 2186 1997 4319 9963 2015 1006 26445 24901 3723 4179 1010 20856 1007 2020 2864 2012 2367 21656 2008 2106 2025 3965 2151 7620 1999 3255 2030 15316 24491 2015 1012 2044 5776 9920 1010 3949 2007 2659 6075 16175 6305 6279 4609 14890 1006 19413 1007 2001 2318 1006 1016 1011 1018 22100 1013 1055 1007 1010 1996 8015 2109 2001 2008 3970 2011 1996 5776 2004 2000 3917 3085 1012 2009 2001 4162 1999 3481 15864 2135 6521 1997 2382 2781 9367 1012 1996 4217 2685 2020 1024 18208 15444 1010 17758 13843 12198 1010 2324 17758 8909 1010 1018 17758 1045 2290 1010 1017 17758 1044 1010 3322 4117 2007 11721 3676 11837 7629 1006 3998 11460 1013 2260 1044 1007 1012 1015 1012 2044 1020 6521 1997 3949 1010 1996 5776 2988 2488 20302 8449 2594 2491 1998 2488 13986 2000 5850 1010 3114 2339 11721 3676 11837 7629 2001 3445 1006 7706 11460 1007 1998 11968 11636 7274 9067 3447 1997 12517 9365 2140 1006 2423 11460 2296 1020 1011 1022 2847 1007 1012 29347 6521 2020 2218 4882 1012 2023 2001 2628 2011 2488 20302 8449 2594 3737 1010 2021 24780 1012 2009 2001 2787 2000 12532 16778 11231 2063 12517 9365 2140 1998 6360 3623 11721 3676 11837 7629 2076 1016 2706 1006 1016 1010 4278 11460 1013 2484 1044 1007 1012 2007 2023 2047 17261 2933 1037 6986 7068 10196 2491 1997 11968 11636 7274 9067 25332 2001 4663 1010 2119 1999 8015 1010 6075 1998 9367 1012 2044 1017 2706 1997 6612 9211 1010 1996 5776 4510 10865 1997 7142 3255 1010 11968 11636 7274 9067 25332 2018 10548 1999 6075 1998 8015 1010 1998 2018 2488 13986 2000 3637 9961 1012 11721 3676 11837 7629 2001 20519 102\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:label: 0_0,1_1,2_0,3_0,4_0,5_1,6_0,7_0,8_0,9_0,10_0,11_0,12_0,13_0,14_0,15_0,16_1,17_1,18_0,19_0 (id_list = [0, 3, 4, 6, 8, 11, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 33, 35, 36, 38])\n",
      "INFO:tensorflow:label: 0_0,1_1,2_0,3_0,4_0,5_1,6_0,7_0,8_0,9_0,10_0,11_0,12_0,13_0,14_0,15_0,16_1,17_1,18_0,19_0 (id = [1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0])\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:guid: train-4\n",
      "INFO:tensorflow:tokens: [CLS] we report the case of a 66 - year - old patient with a medical history of sub ##to ##tal gas ##tre ##ct ##omy for gas ##tric aden ##oca ##rc ##ino ##ma four years ago and arterial hyper ##tension treated with conventional isolation . the patient is bed ##rid ##den by the digest ##ive service , assessed for a long - standing condition characterized by an ##ore ##xia , loss of 12 ki ##los in 6 months ( current weight 42 ki ##los ) , h ##yp ##och ##rom ##ic an ##emia and con ##sti ##pati ##on . physical examination revealed a large tumor of firm consistency , pain ##less , mobile and occupying three - quarters of the abdomen . 1 . given the history of gas ##tric aden ##oca ##rc ##ino ##ma , severe deterioration of general status , con ##sti ##pati ##on and an ##emia , the first clinical suspicion suggested was as ##cite ##s due to car ##cino ##mat ##osis , int ##estinal tumor obstruction or abdominal tumor . analytical data reflected hem ##og ##lo ##bin 7 . 5 g / dl , 3 . 35 million controls , 27 % ha ##ema ##to ##cr ##its , mc ##v 71 . 3 , rd ##w 18 , vs ##g 37 mm / h , cr ##p 24 ##ml ps ##a 0 . 89 2 . 6 ng . liver and digest ##ive tumor markers were an ##od ##yne . gas ##tro ##sco ##py revealed an inflammatory poly ##p in the gas ##tric stump , with no evidence of tumor rec ##ur ##rence . it was impossible to perform an int ##estinal meta ##pl ##asia due to int ##estinal displacement and into ##ler ##ance . contra - pe ##l ##vic ultrasound revealed the presence of a cy ##stic tumor with incomplete sept ##a of mixed an ##ech ##oic content occupying the entire abdominal cavity . left kidney with normal characteristics was identified , not affecting the presence of the right kidney . e left cy ##stic les ##ion finding intra ##ab ##dom ##inal cavity is re ##mit ##ted to our consultation where intra ##ven ##ous ur ##ography was performed with result of right functional ann ##ulation , contra ##lateral normal and great mass effect di ##sp ##la ##cing the digest ##ive cy ##st lateral to the h ##yp ##oco ##nus . the ct scan showed a large cy ##stic mass of 29 . 5 cm x 27 . 5 cm x 16 cm , with multiple well - defined sept ##a and walls occupying almost the entire abdomen . an image is identified in theoretical kidney zone renal pe ##lvis hydro ##ne ##ph ##rot ##ic with compression and displacement of all abdominal structures . 1 . the diagnostic suspicion of giant hydro ##ne ##ph ##rosis secondary to lit ##hia ##sic ob ##st ##ru ##ctive ur ##opa ##thy was evaluated the possibility of per ##cut ##aneous drainage and subsequent ne ##ph ##re ##ct ##omy . a right simple ne ##ph ##re ##ct ##omy was performed by sub ##cos [SEP]\n",
      "INFO:tensorflow:input_ids: 101 2057 3189 1996 2553 1997 1037 5764 1011 2095 1011 2214 5776 2007 1037 2966 2381 1997 4942 3406 9080 3806 7913 6593 16940 2005 3806 12412 16298 24755 11890 5740 2863 2176 2086 3283 1998 25543 23760 29048 5845 2007 7511 12477 1012 1996 5776 2003 2793 14615 4181 2011 1996 17886 3512 2326 1010 14155 2005 1037 2146 1011 3061 4650 7356 2011 2019 5686 14787 1010 3279 1997 2260 11382 10483 1999 1020 2706 1006 2783 3635 4413 11382 10483 1007 1010 1044 22571 11663 21716 2594 2019 17577 1998 9530 16643 24952 2239 1012 3558 7749 3936 1037 2312 13656 1997 3813 18700 1010 3255 3238 1010 4684 1998 13992 2093 1011 7728 1997 1996 13878 1012 1015 1012 2445 1996 2381 1997 3806 12412 16298 24755 11890 5740 2863 1010 5729 26118 1997 2236 3570 1010 9530 16643 24952 2239 1998 2019 17577 1010 1996 2034 6612 10928 4081 2001 2004 17847 2015 2349 2000 2482 21081 18900 12650 1010 20014 19126 13656 27208 2030 21419 13656 1012 17826 2951 7686 19610 8649 4135 8428 1021 1012 1019 1043 1013 21469 1010 1017 1012 3486 2454 7711 1010 2676 1003 5292 14545 3406 26775 12762 1010 11338 2615 6390 1012 1017 1010 16428 2860 2324 1010 5443 2290 4261 3461 1013 1044 1010 13675 2361 2484 19968 8827 2050 1014 1012 6486 1016 1012 1020 12835 1012 11290 1998 17886 3512 13656 16387 2020 2019 7716 9654 1012 3806 13181 9363 7685 3936 2019 20187 26572 2361 1999 1996 3806 12412 22475 1010 2007 2053 3350 1997 13656 28667 3126 24413 1012 2009 2001 5263 2000 4685 2019 20014 19126 18804 24759 15396 2349 2000 20014 19126 13508 1998 2046 3917 6651 1012 24528 1011 21877 2140 7903 27312 3936 1996 3739 1997 1037 22330 10074 13656 2007 12958 17419 2050 1997 3816 2019 15937 19419 4180 13992 1996 2972 21419 17790 1012 2187 14234 2007 3671 6459 2001 4453 1010 2025 12473 1996 3739 1997 1996 2157 14234 1012 1041 2187 22330 10074 4649 3258 4531 26721 7875 9527 13290 17790 2003 2128 22930 3064 2000 2256 16053 2073 26721 8159 3560 24471 9888 2001 2864 2007 2765 1997 2157 8360 5754 9513 1010 24528 28277 3671 1998 2307 3742 3466 4487 13102 2721 6129 1996 17886 3512 22330 3367 11457 2000 1996 1044 22571 24163 10182 1012 1996 14931 13594 3662 1037 2312 22330 10074 3742 1997 2756 1012 1019 4642 1060 2676 1012 1019 4642 1060 2385 4642 1010 2007 3674 2092 1011 4225 17419 2050 1998 3681 13992 2471 1996 2972 13878 1012 2019 3746 2003 4453 1999 9373 14234 4224 25125 21877 28530 18479 2638 8458 21709 2594 2007 13379 1998 13508 1997 2035 21419 5090 1012 1015 1012 1996 16474 10928 1997 5016 18479 2638 8458 29166 3905 2000 5507 12995 19570 27885 3367 6820 15277 24471 29477 16921 2001 16330 1996 6061 1997 2566 12690 17191 11987 1998 4745 11265 8458 2890 6593 16940 1012 1037 2157 3722 11265 8458 2890 6593 16940 2001 2864 2011 4942 13186 102\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:label: 0_0,1_0,2_1,3_1,4_1,5_0,6_0,7_1,8_0,9_0,10_0,11_0,12_0,13_0,14_1,15_0,16_1,17_0,18_1,19_0 (id_list = [0, 2, 5, 7, 9, 10, 12, 15, 16, 18, 20, 22, 24, 26, 29, 30, 33, 34, 37, 38])\n",
      "INFO:tensorflow:label: 0_0,1_0,2_1,3_1,4_1,5_0,6_0,7_1,8_0,9_0,10_0,11_0,12_0,13_0,14_1,15_0,16_1,17_0,18_1,19_0 (id = [1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0])\n",
      "INFO:tensorflow:***** Running training *****\n",
      "INFO:tensorflow:  Num examples = 300\n",
      "INFO:tensorflow:  Batch size = 4\n",
      "INFO:tensorflow:  Num steps = 225\n"
     ]
    }
   ],
   "source": [
    "if FLAGS.do_train:\n",
    "        train_file = os.path.join(output_dir, \"train.tf_record\")\n",
    "        file_based_convert_examples_to_features(\n",
    "            train_examples,label_list=label_list, max_seq_length = FLAGS.max_seq_length, tokenizer=tokenizer,output_file=train_file)\n",
    "        tf.logging.info(\"***** Running training *****\")\n",
    "        tf.logging.info(\"  Num examples = %d\", len(train_examples))\n",
    "        tf.logging.info(\"  Batch size = %d\", FLAGS.train_batch_size)\n",
    "        tf.logging.info(\"  Num steps = %d\", num_train_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d1b400c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\u1111995\\AppData\\Local\\Temp/ipykernel_17112/2590143856.py:6: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_input_fn = file_based_input_fn_builder(\n",
    "            input_file=train_file,\n",
    "            seq_length=FLAGS.max_seq_length,\n",
    "            is_training=True,\n",
    "            drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cd1b9d63",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n",
      "INFO:tensorflow:training_loop marked as finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.tpu.tpu_estimator.TPUEstimator at 0x149101bea88>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae7509a",
   "metadata": {},
   "source": [
    "### EvalExamples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "87f5ab89",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = r\"C:\\Users\\u1111995\\Desktop\\project 2\\Codie_Data\\Data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4f6d2675",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputExample(object):\n",
    "    \"\"\"A single training/test example for simple sequence classification.\"\"\"\n",
    "\n",
    "    def __init__(self, guid, text_a, label, text_b=None):\n",
    "        self.guid = guid\n",
    "        self.text_a = text_a\n",
    "        self.text_b = text_b\n",
    "        self.label = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "af6892b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_examples(gk, set_type):\n",
    "    examples = []\n",
    "    for i in range(len(gk)):\n",
    "      #  if i == 0:\n",
    "      #      continue\n",
    "        guid = \"%s-%s\" % (set_type, i)\n",
    "        label = tokenization.convert_to_unicode(gk.label[i])\n",
    "        text_a = tokenization.convert_to_unicode(gk.notes[i])\n",
    "        examples.append(\n",
    "                InputExample(guid=guid, text_a=text_a,label=label,text_b=None))\n",
    "    return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0a1056b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>articleID</th>\n",
       "      <th>notes</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>129</td>\n",
       "      <td>S0212-16112005000400011-1</td>\n",
       "      <td>The patient, a 55-year-old man without known a...</td>\n",
       "      <td>0_0,1_0,2_0,3_1,4_0,5_0,6_0,7_0,8_1,9_0,10_0,1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>183</td>\n",
       "      <td>S0365-66912006000600011-1</td>\n",
       "      <td>A 13-year-old male patient is diagnosed with p...</td>\n",
       "      <td>0_0,1_0,2_1,3_0,4_0,5_0,6_0,7_0,8_0,9_0,10_0,1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>216</td>\n",
       "      <td>S0365-66912011000800006-1</td>\n",
       "      <td>An 83-year-old male with advanced Alzheimer's ...</td>\n",
       "      <td>0_0,1_0,2_0,3_0,4_0,5_0,6_1,7_0,8_0,9_1,10_0,1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>182</td>\n",
       "      <td>S0365-66912006000600010-1</td>\n",
       "      <td>A 16-year-old woman was referred for consultat...</td>\n",
       "      <td>0_0,1_0,2_0,3_0,4_0,5_0,6_1,7_0,8_0,9_0,10_0,1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>349</td>\n",
       "      <td>S1130-14732006000300007-1</td>\n",
       "      <td>A 28-year-old male who was admitted to the eme...</td>\n",
       "      <td>0_0,1_0,2_0,3_1,4_0,5_1,6_1,7_1,8_1,9_0,10_1,1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>141</td>\n",
       "      <td>S0212-16112012000400060-1</td>\n",
       "      <td>A 31-year-old woman with a history of multiple...</td>\n",
       "      <td>0_0,1_0,2_0,3_1,4_1,5_0,6_1,7_1,8_0,9_1,10_0,1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>72</td>\n",
       "      <td>S0210-48062007000700014-1</td>\n",
       "      <td>A 46-year-old male, with no relevant past medi...</td>\n",
       "      <td>0_0,1_0,2_0,3_0,4_1,5_0,6_0,7_0,8_0,9_0,10_0,1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>24</td>\n",
       "      <td>S0004-06142007000500011-1</td>\n",
       "      <td>An 11-year-old white girl with a history of pr...</td>\n",
       "      <td>0_0,1_0,2_0,3_1,4_1,5_0,6_0,7_1,8_0,9_0,10_0,1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>449</td>\n",
       "      <td>S1139-76322015000100012-3</td>\n",
       "      <td>A nine-month-old male presented with intense p...</td>\n",
       "      <td>0_0,1_1,2_0,3_0,4_0,5_0,6_0,7_0,8_1,9_0,10_0,1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>292</td>\n",
       "      <td>S1130-01082009000700012-1</td>\n",
       "      <td>A 53-year-old male presented with severe pain ...</td>\n",
       "      <td>0_0,1_0,2_0,3_1,4_0,5_0,6_0,7_0,8_0,9_1,10_0,1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0                  articleID  \\\n",
       "0          129  S0212-16112005000400011-1   \n",
       "1          183  S0365-66912006000600011-1   \n",
       "2          216  S0365-66912011000800006-1   \n",
       "3          182  S0365-66912006000600010-1   \n",
       "4          349  S1130-14732006000300007-1   \n",
       "..         ...                        ...   \n",
       "95         141  S0212-16112012000400060-1   \n",
       "96          72  S0210-48062007000700014-1   \n",
       "97          24  S0004-06142007000500011-1   \n",
       "98         449  S1139-76322015000100012-3   \n",
       "99         292  S1130-01082009000700012-1   \n",
       "\n",
       "                                                notes  \\\n",
       "0   The patient, a 55-year-old man without known a...   \n",
       "1   A 13-year-old male patient is diagnosed with p...   \n",
       "2   An 83-year-old male with advanced Alzheimer's ...   \n",
       "3   A 16-year-old woman was referred for consultat...   \n",
       "4   A 28-year-old male who was admitted to the eme...   \n",
       "..                                                ...   \n",
       "95  A 31-year-old woman with a history of multiple...   \n",
       "96  A 46-year-old male, with no relevant past medi...   \n",
       "97  An 11-year-old white girl with a history of pr...   \n",
       "98  A nine-month-old male presented with intense p...   \n",
       "99  A 53-year-old male presented with severe pain ...   \n",
       "\n",
       "                                                label  \n",
       "0   0_0,1_0,2_0,3_1,4_0,5_0,6_0,7_0,8_1,9_0,10_0,1...  \n",
       "1   0_0,1_0,2_1,3_0,4_0,5_0,6_0,7_0,8_0,9_0,10_0,1...  \n",
       "2   0_0,1_0,2_0,3_0,4_0,5_0,6_1,7_0,8_0,9_1,10_0,1...  \n",
       "3   0_0,1_0,2_0,3_0,4_0,5_0,6_1,7_0,8_0,9_0,10_0,1...  \n",
       "4   0_0,1_0,2_0,3_1,4_0,5_1,6_1,7_1,8_1,9_0,10_1,1...  \n",
       "..                                                ...  \n",
       "95  0_0,1_0,2_0,3_1,4_1,5_0,6_1,7_1,8_0,9_1,10_0,1...  \n",
       "96  0_0,1_0,2_0,3_0,4_1,5_0,6_0,7_0,8_0,9_0,10_0,1...  \n",
       "97  0_0,1_0,2_0,3_1,4_1,5_0,6_0,7_1,8_0,9_0,10_0,1...  \n",
       "98  0_0,1_1,2_0,3_0,4_0,5_0,6_0,7_0,8_1,9_0,10_0,1...  \n",
       "99  0_0,1_0,2_0,3_1,4_0,5_0,6_0,7_0,8_0,9_1,10_0,1...  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev = pd.read_csv(os.path.join(data_dir, \"codievalidation16.tsv\"),sep=\"\\t\")\n",
    "dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3e3c12e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dev_examples(data_dir):\n",
    "    return _create_examples(dev, \"dev\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b92792ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 0 of 100\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:guid: dev-0\n",
      "INFO:tensorflow:tokens: [CLS] the patient , a 55 - year - old man without known all ##er ##gies diagnosed with gas ##tric aden ##oca ##rc ##ino ##ma , was admitted in november 2001 to the digest ##ive service of son du ##ret ##a hospital where a sub ##to ##tal gas ##tre ##ct ##omy and reconstruction of the gas ##tro ##jer ##o ii were performed . five days after surgery the patient ' s clinical condition requires the prescription of artificial nutrition , starting central administration of t ##p ##n . the preparation administered is ka ##bi ##mi ##x ##® ( see detailed composition in table i ) , a diet of 2 , 55 ##3 ki ##lo ##cal ##ories supplemented in the a care service with alternating days with a multi ##vita ##min preparation ##® ( vi ##tp ##m ##v ) . 48 hours after parent ##eral nutrition was established , it was decided to change the type of diet , in order to administer a formula more adjusted to the nutritional requirements of the patient so that the patient receives the ka ##bi ##ven ##® ol ##igo ##ele ##ments . twenty - four hours after the start of in ##fusion of this diet , the patient presents a significant di ##sse ##minated pr ##uri ##tic skin rash requiring oral dex ##ch ##lor ##ph ##eni ##ram ##ine administration . mechanical complications cause loss of central ve ##nous access due to the removal of t ##p ##n and oral tolerance starts . on the eighth day after surgery the patient complained of severe abdominal pain requiring an ex ##pl ##ora ##tory lap ##aro ##tom ##y which detected an abs ##ces ##s with bi ##lia ##ry collection . t ##p ##n is restarted by administering the ka ##bi ##ven ##® diet supplemented with the aforementioned pm ##v . a few hours after the start of in ##fusion , a new episode of di ##sse ##minated pr ##uri ##tic skin rash occurs , leading to permanent disco ##nti ##nu ##ation of t ##p ##n . 1 . in march 2003 , the patient came to the emergency department of that hospital for fever and abdominal pain , being diagnosed with cho ##lang ##itis and admitted to the digest ##ive service . together with anti ##biotic and anal ##ges ##ic treatment , an absolute diet is indicated and , due to a history of hyper ##sen ##sit ##ivity , the prescription of p ##nt is avoided , with er ##ythe ##ma or amino acid and glucose solution ( amino ##ven ##® , table iii ) , without mentioning after 48 hours , lip ##id em ##ulsion was added ( intra ##lip ##id ##® 10 % , table iii ) by the central route without any complications . on this occasion , it was decided not to administer pm ##v or trace elements to the patient . after several days of admission , progression of the gas ##tric neo ##form ##ative process was observed and the patient died in april 2003 . [SEP]\n",
      "INFO:tensorflow:input_ids: 101 1996 5776 1010 1037 4583 1011 2095 1011 2214 2158 2302 2124 2035 2121 17252 11441 2007 3806 12412 16298 24755 11890 5740 2863 1010 2001 4914 1999 2281 2541 2000 1996 17886 3512 2326 1997 2365 4241 13465 2050 2902 2073 1037 4942 3406 9080 3806 7913 6593 16940 1998 8735 1997 1996 3806 13181 20009 2080 2462 2020 2864 1012 2274 2420 2044 5970 1996 5776 1005 1055 6612 4650 5942 1996 20422 1997 7976 14266 1010 3225 2430 3447 1997 1056 2361 2078 1012 1996 7547 8564 2003 10556 5638 4328 2595 29656 1006 2156 6851 5512 1999 2795 1045 1007 1010 1037 8738 1997 1016 1010 4583 2509 11382 4135 9289 18909 20585 1999 1996 1037 2729 2326 2007 15122 2420 2007 1037 4800 28403 10020 7547 29656 1006 6819 25856 2213 2615 1007 1012 4466 2847 2044 6687 21673 14266 2001 2511 1010 2009 2001 2787 2000 2689 1996 2828 1997 8738 1010 1999 2344 2000 21497 1037 5675 2062 10426 2000 1996 28268 5918 1997 1996 5776 2061 2008 1996 5776 8267 1996 10556 5638 8159 29656 19330 14031 12260 8163 1012 3174 1011 2176 2847 2044 1996 2707 1997 1999 20523 1997 2023 8738 1010 1996 5776 7534 1037 3278 4487 11393 26972 10975 9496 4588 3096 23438 9034 8700 20647 2818 10626 8458 18595 6444 3170 3447 1012 6228 12763 3426 3279 1997 2430 2310 18674 3229 2349 2000 1996 8208 1997 1056 2361 2078 1998 8700 13986 4627 1012 2006 1996 5964 2154 2044 5970 1996 5776 10865 1997 5729 21419 3255 9034 2019 4654 24759 6525 7062 5001 10464 20389 2100 2029 11156 2019 14689 9623 2015 2007 12170 6632 2854 3074 1012 1056 2361 2078 2003 25606 2011 28965 1996 10556 5638 8159 29656 8738 20585 2007 1996 17289 7610 2615 1012 1037 2261 2847 2044 1996 2707 1997 1999 20523 1010 1037 2047 2792 1997 4487 11393 26972 10975 9496 4588 3096 23438 5158 1010 2877 2000 4568 12532 16778 11231 3370 1997 1056 2361 2078 1012 1015 1012 1999 2233 2494 1010 1996 5776 2234 2000 1996 5057 2533 1997 2008 2902 2005 9016 1998 21419 3255 1010 2108 11441 2007 16480 25023 13706 1998 4914 2000 1996 17886 3512 2326 1012 2362 2007 3424 26591 1998 20302 8449 2594 3949 1010 2019 7619 8738 2003 5393 1998 1010 2349 2000 1037 2381 1997 23760 5054 28032 7730 1010 1996 20422 1997 1052 3372 2003 9511 1010 2007 9413 26688 2863 2030 13096 5648 1998 18423 5576 1006 13096 8159 29656 1010 2795 3523 1007 1010 2302 18625 2044 4466 2847 1010 5423 3593 7861 23316 2001 2794 1006 26721 15000 3593 29656 2184 1003 1010 2795 3523 1007 2011 1996 2430 2799 2302 2151 12763 1012 2006 2023 6686 1010 2009 2001 2787 2025 2000 21497 7610 2615 2030 7637 3787 2000 1996 5776 1012 2044 2195 2420 1997 9634 1010 14967 1997 1996 3806 12412 9253 14192 8082 2832 2001 5159 1998 1996 5776 2351 1999 2258 2494 1012 102 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:label: 0_0,1_0,2_0,3_1,4_0,5_0,6_0,7_0,8_1,9_0,10_0,11_0,12_0,13_0,14_1,15_0,16_1,17_0,18_0,19_0 (id_list = [0, 2, 4, 7, 8, 10, 12, 14, 17, 18, 20, 22, 24, 26, 29, 30, 33, 34, 36, 38])\n",
      "INFO:tensorflow:label: 0_0,1_0,2_0,3_1,4_0,5_0,6_0,7_0,8_1,9_0,10_0,11_0,12_0,13_0,14_1,15_0,16_1,17_0,18_0,19_0 (id = [1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0])\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:guid: dev-1\n",
      "INFO:tensorflow:tokens: [CLS] a 13 - year - old male patient is diagnosed with poor vision . fetal strict ##ure was a short child with a 133 cm height , bra ##chy ##mo ##rp ##hy and bra ##chy ##da ##ct ##yl ##y in all four limbs . the patient had a corrected ref ##ractive error of - 13 . 00 - 6 . 50 to 1 ##o in the right eye and - 16 . 00 - 6 . 25 to 179 ##o in the left eye . this correction achieved a visual ac ##uity of 0 . 4 and 0 . 2 respectively . there was no mono ##cular dip ##lo ##pia or intrinsic o ##cular mo ##tility findings . horizontal corn ##eal diameter was 12 . 0 mm in both eyes and pac ##hy ##metry was 61 ##3 and 61 ##1 mm respectively . the anterior chamber was narrow , showing bilateral ir ##ido ##don ##sis . micro ##sphere ##s with anterior displacement of both crystalline lenses within the posterior chamber were evidenced . intra ##oc ##ular pressure was 20 mm ##hg bilateral ##ly . go ##nio ##sco ##py showed a symmetric narrow angle in both eyes grade ii according to sc ##ha ##ffer . examination by corn ##eal topography or ##can - ii ( ba ##ush and lo ##mb ct , u . s . a . ) and examination of the eye fund ##us showed no abnormalities . to prevent angular closure , n ##d : ya ##g laser ir ##ido ##tom ##y was performed in both eyes at 10 and 2 hours , respectively . given the stability of vision and the absence of dip ##lo ##pia , a conservative attitude was adopted according to the wishes of the patient ' s family by controlling visual ac ##uity , intra ##oc ##ular pressure , photographic documentation and visual field damage . reviewing his family background , the patient was identified as the child in a family of eight , in which - brother - in - law and bra ##chy ##da - a brother and two sisters presented sp ##her ##op ##hak ##ia , bra ##cchi ##mo ##rp ##hia parents were healthy and none of the children had offspring . [SEP]\n",
      "INFO:tensorflow:input_ids: 101 1037 2410 1011 2095 1011 2214 3287 5776 2003 11441 2007 3532 4432 1012 25972 9384 5397 2001 1037 2460 2775 2007 1037 14506 4642 4578 1010 11655 11714 5302 14536 10536 1998 11655 11714 2850 6593 8516 2100 1999 2035 2176 10726 1012 1996 5776 2018 1037 13371 25416 26884 7561 1997 1011 2410 1012 4002 1011 1020 1012 2753 2000 1015 2080 1999 1996 2157 3239 1998 1011 2385 1012 4002 1011 1020 1012 2423 2000 20311 2080 1999 1996 2187 3239 1012 2023 18140 4719 1037 5107 9353 18518 1997 1014 1012 1018 1998 1014 1012 1016 4414 1012 2045 2001 2053 18847 15431 16510 4135 19312 2030 23807 1051 15431 9587 18724 9556 1012 9876 9781 15879 6705 2001 2260 1012 1014 3461 1999 2119 2159 1998 14397 10536 24327 2001 6079 2509 1998 6079 2487 3461 4414 1012 1996 15099 4574 2001 4867 1010 4760 17758 20868 13820 5280 6190 1012 12702 23874 2015 2007 15099 13508 1997 2119 24628 15072 2306 1996 15219 4574 2020 21328 1012 26721 10085 7934 3778 2001 2322 3461 25619 17758 2135 1012 2175 27678 9363 7685 3662 1037 19490 4867 6466 1999 2119 2159 3694 2462 2429 2000 8040 3270 12494 1012 7749 2011 9781 15879 21535 2030 9336 1011 2462 1006 8670 20668 1998 8840 14905 14931 1010 1057 1012 1055 1012 1037 1012 1007 1998 7749 1997 1996 3239 4636 2271 3662 2053 28828 1012 2000 4652 16108 8503 1010 1050 2094 1024 8038 2290 9138 20868 13820 20389 2100 2001 2864 1999 2119 2159 2012 2184 1998 1016 2847 1010 4414 1012 2445 1996 9211 1997 4432 1998 1996 6438 1997 16510 4135 19312 1010 1037 4603 7729 2001 4233 2429 2000 1996 8996 1997 1996 5776 1005 1055 2155 2011 9756 5107 9353 18518 1010 26721 10085 7934 3778 1010 12416 12653 1998 5107 2492 4053 1012 15252 2010 2155 4281 1010 1996 5776 2001 4453 2004 1996 2775 1999 1037 2155 1997 2809 1010 1999 2029 1011 2567 1011 1999 1011 2375 1998 11655 11714 2850 1011 1037 2567 1998 2048 5208 3591 11867 5886 7361 20459 2401 1010 11655 25955 5302 14536 12995 3008 2020 7965 1998 3904 1997 1996 2336 2018 13195 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:label: 0_0,1_0,2_1,3_0,4_0,5_0,6_0,7_0,8_0,9_0,10_0,11_0,12_0,13_0,14_0,15_0,16_0,17_1,18_0,19_0 (id_list = [0, 2, 5, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32, 35, 36, 38])\n",
      "INFO:tensorflow:label: 0_0,1_0,2_1,3_0,4_0,5_0,6_0,7_0,8_0,9_0,10_0,11_0,12_0,13_0,14_0,15_0,16_0,17_1,18_0,19_0 (id = [1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0])\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:guid: dev-2\n",
      "INFO:tensorflow:tokens: [CLS] an 83 - year - old male with advanced alzheimer ' s disease , insulin - dependent dia ##bet ##ic with 35 years of evolution , who came to our emergency department due to a 2 - day history of o ##cular pain in the right eye . the va could not be object ##ified due to lack of cooperation . the evaluation of the anterior segment determined a 2 . 5 ##mm diameter corn ##eal ul ##cera ##tive les ##ion with a central per ##for ##ating end ##oth ##elial por ##e of approximately 1 ##mm , without con ##com ##itan ##t infectious or inflammatory process . the patient had no history of trauma . with the diagnosis of sterile non - traumatic corn ##eal per ##for ##ation to fi ##lia ##tion , the urgent closure of the les ##ion was performed . under topical an ##esthesia and in the operating room to facilitate collaboration , a tape ##il ##® patch was prepared , which was shortened so as to overcome the ul ##cera ##tion edges , for full recovery . after hydra ##tion with saline solution for 5 seconds , it was applied immediately with the active part ( part ##ite ) of the corn ##eal defect , pressing and gently moist ##ening the sponge for 3 minutes with a firm force ##ps until secure . 1 . without removing excess material , the eye was o ##cc ##lu ##ded . after 36 hours of o ##cc ##lusion , the sponge was not detached from the application site and a fi ##bri ##no ##id material o ##cc ##lu ##ding the per ##for ##ating end ##oth ##elial por ##e was observed . no sponge remains were found displaced or in the con ##jun ##ct ##iva ##l sac funds . a therapeutic lens was safely applied and it was started with topical anti ##biotic , cy ##cl ##ope ##pt ##ide and med ##ro ##xy ##pro ##ges ##ter ##one treatment . 72 hours after application , corn ##eal thin ##ning persisted over the per ##for ##ation site , with complete closure and good anterior chamber depth . subsequent controls one week and one month later confirmed total corn ##eal closure , which was able to remove the therapeutic lens and the medical treatment described . [SEP]\n",
      "INFO:tensorflow:input_ids: 101 2019 6640 1011 2095 1011 2214 3287 2007 3935 21901 1005 1055 4295 1010 22597 1011 7790 22939 20915 2594 2007 3486 2086 1997 6622 1010 2040 2234 2000 2256 5057 2533 2349 2000 1037 1016 1011 2154 2381 1997 1051 15431 3255 1999 1996 2157 3239 1012 1996 12436 2071 2025 2022 4874 7810 2349 2000 3768 1997 6792 1012 1996 9312 1997 1996 15099 6903 4340 1037 1016 1012 1019 7382 6705 9781 15879 17359 19357 6024 4649 3258 2007 1037 2430 2566 29278 5844 2203 14573 24587 18499 2063 1997 3155 1015 7382 1010 2302 9530 9006 25451 2102 16514 2030 20187 2832 1012 1996 5776 2018 2053 2381 1997 12603 1012 2007 1996 11616 1997 25403 2512 1011 19686 9781 15879 2566 29278 3370 2000 10882 6632 3508 1010 1996 13661 8503 1997 1996 4649 3258 2001 2864 1012 2104 25665 2019 25344 1998 1999 1996 4082 2282 2000 10956 5792 1010 1037 6823 4014 29656 8983 2001 4810 1010 2029 2001 12641 2061 2004 2000 9462 1996 17359 19357 3508 7926 1010 2005 2440 7233 1012 2044 26018 3508 2007 28413 5576 2005 1019 3823 1010 2009 2001 4162 3202 2007 1996 3161 2112 1006 2112 4221 1007 1997 1996 9781 15879 21262 1010 7827 1998 5251 11052 7406 1996 25742 2005 1017 2781 2007 1037 3813 2486 4523 2127 5851 1012 1015 1012 2302 9268 9987 3430 1010 1996 3239 2001 1051 9468 7630 5732 1012 2044 4029 2847 1997 1051 9468 24117 1010 1996 25742 2001 2025 12230 2013 1996 4646 2609 1998 1037 10882 23736 3630 3593 3430 1051 9468 7630 4667 1996 2566 29278 5844 2203 14573 24587 18499 2063 2001 5159 1012 2053 25742 3464 2020 2179 12936 2030 1999 1996 9530 19792 6593 11444 2140 17266 5029 1012 1037 17261 10014 2001 9689 4162 1998 2009 2001 2318 2007 25665 3424 26591 1010 22330 20464 17635 13876 5178 1998 19960 3217 18037 21572 8449 3334 5643 3949 1012 5824 2847 2044 4646 1010 9781 15879 4857 5582 19035 2058 1996 2566 29278 3370 2609 1010 2007 3143 8503 1998 2204 15099 4574 5995 1012 4745 7711 2028 2733 1998 2028 3204 2101 4484 2561 9781 15879 8503 1010 2029 2001 2583 2000 6366 1996 17261 10014 1998 1996 2966 3949 2649 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:label: 0_0,1_0,2_0,3_0,4_0,5_0,6_1,7_0,8_0,9_1,10_0,11_1,12_0,13_1,14_0,15_0,16_1,17_1,18_0,19_0 (id_list = [0, 2, 4, 6, 8, 10, 13, 14, 16, 19, 20, 23, 24, 27, 28, 30, 33, 35, 36, 38])\n",
      "INFO:tensorflow:label: 0_0,1_0,2_0,3_0,4_0,5_0,6_1,7_0,8_0,9_1,10_0,11_1,12_0,13_1,14_0,15_0,16_1,17_1,18_0,19_0 (id = [1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0])\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:guid: dev-3\n",
      "INFO:tensorflow:tokens: [CLS] a 16 - year - old woman was referred for consultation due to visual difficulties , « as a part of the girl i don ’ t see , especially since 3 weeks ago » . his mother says that ' he has changed from being an active girl to being light ##ened , with difficulty thinking , talking and now sees bad . ' since the age of 7 years she has had seizures that are difficult to control . her treatment was car ##ba ##ma ##ze ##pine , h ##yd ##anto ##in and for 3 months top ##ama ##x 125 mg daily . the last exploration performed one year earlier was normal . spontaneous visual ac ##uity ( va ) was 1 in both eyes , with normal anterior void ##ing bio ##mics . the pupils were iso ##cho ##ric and norm ##ore ##active . fund ##os ##co ##py showed no abnormalities . a non - concurrent left hem ##iano ##ps ##ia was observed in the computer ##ized camp ##ime ##try . the color test showed no alterations in any eye . a ga ##do ##lini ##um - enhanced magnetic resonance imaging ( mri ) of the brain was normal , as well as a diffusion - weighted mri . the rest of the neurological examination was normal . the suspicion of a toxic phenomenon by top ##ama ##x was suspended progressively , with subjective improvement of the patient and partial recovery of the visual field . [SEP]\n",
      "INFO:tensorflow:input_ids: 101 1037 2385 1011 2095 1011 2214 2450 2001 3615 2005 16053 2349 2000 5107 8190 1010 1077 2004 1037 2112 1997 1996 2611 1045 2123 1521 1056 2156 1010 2926 2144 1017 3134 3283 1090 1012 2010 2388 2758 2008 1005 2002 2038 2904 2013 2108 2019 3161 2611 2000 2108 2422 6675 1010 2007 7669 3241 1010 3331 1998 2085 5927 2919 1012 1005 2144 1996 2287 1997 1021 2086 2016 2038 2018 25750 2008 2024 3697 2000 2491 1012 2014 3949 2001 2482 3676 2863 4371 19265 1010 1044 25688 21634 2378 1998 2005 1017 2706 2327 8067 2595 8732 11460 3679 1012 1996 2197 8993 2864 2028 2095 3041 2001 3671 1012 17630 5107 9353 18518 1006 12436 1007 2001 1015 1999 2119 2159 1010 2007 3671 15099 11675 2075 16012 22924 1012 1996 7391 2020 11163 9905 7277 1998 13373 5686 19620 1012 4636 2891 3597 7685 3662 2053 28828 1012 1037 2512 1011 16483 2187 19610 15668 4523 2401 2001 5159 1999 1996 3274 3550 3409 14428 11129 1012 1996 3609 3231 3662 2053 16705 1999 2151 3239 1012 1037 11721 3527 22153 2819 1011 9412 8060 17011 12126 1006 27011 1007 1997 1996 4167 2001 3671 1010 2004 2092 2004 1037 19241 1011 18215 27011 1012 1996 2717 1997 1996 23130 7749 2001 3671 1012 1996 10928 1997 1037 11704 9575 2011 2327 8067 2595 2001 6731 20519 1010 2007 20714 7620 1997 1996 5776 1998 7704 7233 1997 1996 5107 2492 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:label: 0_0,1_0,2_0,3_0,4_0,5_0,6_1,7_0,8_0,9_0,10_0,11_0,12_0,13_0,14_0,15_0,16_1,17_1,18_0,19_0 (id_list = [0, 2, 4, 6, 8, 10, 13, 14, 16, 18, 20, 22, 24, 26, 28, 30, 33, 35, 36, 38])\n",
      "INFO:tensorflow:label: 0_0,1_0,2_0,3_0,4_0,5_0,6_1,7_0,8_0,9_0,10_0,11_0,12_0,13_0,14_0,15_0,16_1,17_1,18_0,19_0 (id = [1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0])\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:guid: dev-4\n",
      "INFO:tensorflow:tokens: [CLS] a 28 - year - old male who was admitted to the emergency department of a regional hospital presented , as a result of a car accident , multiple trauma with a 6 ##° fracture costa ##l arch and right - sided ad ##ren ##al hem ##ato ##ma right - sided ligament lux ##ation , right - sided renal injury right - sided , right - sided renal injury left ad ##ren ##al mass with poly ##tra ##uma . the patient required oro ##tra ##che ##al int ##uba ##tion and ventilation assisted by respiratory failure , and blood trans ##fusion ##s for acute an ##emia , admitted to the ic ##u . ex ##tub ##ated 48 hours later without incidents , the patient was transferred to the hospital ward 24 hours later , where she remained ten days , with placement of a plaster in the right lower limb . from hospital discharge , 13 days after the trauma , the patient presents back - lu ##mba ##r pain , initially found to have renal trauma , which in the last 7 days is associated with subjective sensation of con ##sti ##pati ##on plus lower ex ##tre ##mit ##ies discomfort for par ##esthesia . one month after the trauma , the patient came to the regional hospital with thor ##ac ##ic and lu ##mba ##r spine x - rays . an increase in lateral inter ##sp ##ino ##us distance was observed , with a minimum anterior ve ##rte ##bra ##l body di ##sl ##ocation , above and above the t ##11 . mri was performed in the area in which the presence of hem ##ato ##mas in the canal was ruled out , confirming the x - ray findings , and with a doubtful image of spinal cord con ##tus ##ion . blood is also present at the level of the inter ##sp ##ino ##us ligament . the patient is admitted to our service . 1 . on admission , the patient had mild para ##par ##esis ( 4 + / 5 ) predominantly pro ##xi ##mal , with no sensory deficit ##s , mild bilateral symmetrical hyper ##re ##fle ##xia , without signs of pyramid ##al release . ct is performed , which in the axial sections shows the existence of an abnormal disposition of the face ##ts t ##11 - t ##12 , with ste ##nosis of the canal at this level , and the existence of a sign of the fractured sa ##git ##tal face ##t t ##12 . 1 . the patient was operated on by means of an ex posterior approach , performing a cure ##tte ##ct ##omy for a complete mag ##tra ##ction - auto ##log ##ous fix ##ation quasi - graf ##t at the level of both , cure ##tta ##ge of the superior ve ##na ca ##va - t ##12 , reduction . the patient evolved favorably , his neurological symptoms disappeared in the first week , being discharged without pain and walking normally . [SEP]\n",
      "INFO:tensorflow:input_ids: 101 1037 2654 1011 2095 1011 2214 3287 2040 2001 4914 2000 1996 5057 2533 1997 1037 3164 2902 3591 1010 2004 1037 2765 1997 1037 2482 4926 1010 3674 12603 2007 1037 1020 7737 19583 6849 2140 7905 1998 2157 1011 11536 4748 7389 2389 19610 10610 2863 2157 1011 11536 25641 28359 3370 1010 2157 1011 11536 25125 4544 2157 1011 11536 1010 2157 1011 11536 25125 4544 2187 4748 7389 2389 3742 2007 26572 6494 12248 1012 1996 5776 3223 20298 6494 5403 2389 20014 19761 3508 1998 19536 7197 2011 16464 4945 1010 1998 2668 9099 20523 2015 2005 11325 2019 17577 1010 4914 2000 1996 24582 2226 1012 4654 28251 4383 4466 2847 2101 2302 10444 1010 1996 5776 2001 4015 2000 1996 2902 4829 2484 2847 2101 1010 2073 2016 2815 2702 2420 1010 2007 11073 1997 1037 15673 1999 1996 2157 2896 15291 1012 2013 2902 11889 1010 2410 2420 2044 1996 12603 1010 1996 5776 7534 2067 1011 11320 11201 2099 3255 1010 3322 2179 2000 2031 25125 12603 1010 2029 1999 1996 2197 1021 2420 2003 3378 2007 20714 8742 1997 9530 16643 24952 2239 4606 2896 4654 7913 22930 3111 17964 2005 11968 25344 1012 2028 3204 2044 1996 12603 1010 1996 5776 2234 2000 1996 3164 2902 2007 15321 6305 2594 1998 11320 11201 2099 8560 1060 1011 9938 1012 2019 3623 1999 11457 6970 13102 5740 2271 3292 2001 5159 1010 2007 1037 6263 15099 2310 19731 10024 2140 2303 4487 14540 23909 1010 2682 1998 2682 1996 1056 14526 1012 27011 2001 2864 1999 1996 2181 1999 2029 1996 3739 1997 19610 10610 9335 1999 1996 5033 2001 5451 2041 1010 19195 1996 1060 1011 4097 9556 1010 1998 2007 1037 21888 3746 1997 16492 11601 9530 5809 3258 1012 2668 2003 2036 2556 2012 1996 2504 1997 1996 6970 13102 5740 2271 25641 1012 1996 5776 2003 4914 2000 2256 2326 1012 1015 1012 2006 9634 1010 1996 5776 2018 10256 11498 19362 19009 1006 1018 1009 1013 1019 1007 9197 4013 9048 9067 1010 2007 2053 16792 15074 2015 1010 10256 17758 23476 23760 2890 21031 14787 1010 2302 5751 1997 11918 2389 2713 1012 14931 2003 2864 1010 2029 1999 1996 26819 5433 3065 1996 4598 1997 2019 19470 22137 1997 1996 2227 3215 1056 14526 1011 1056 12521 1010 2007 26261 27109 1997 1996 5033 2012 2023 2504 1010 1998 1996 4598 1997 1037 3696 1997 1996 21726 7842 23806 9080 2227 2102 1056 12521 1012 1015 1012 1996 5776 2001 3498 2006 2011 2965 1997 2019 4654 15219 3921 1010 4488 1037 9526 4674 6593 16940 2005 1037 3143 23848 6494 7542 1011 8285 21197 3560 8081 3370 17982 1011 22160 2102 2012 1996 2504 1997 2119 1010 9526 5946 3351 1997 1996 6020 2310 2532 6187 3567 1011 1056 12521 1010 7312 1012 1996 5776 7964 27597 1010 2010 23130 8030 5419 1999 1996 2034 2733 1010 2108 14374 2302 3255 1998 3788 5373 1012 102 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:label: 0_0,1_0,2_0,3_1,4_0,5_1,6_1,7_1,8_1,9_0,10_1,11_0,12_1,13_0,14_0,15_0,16_1,17_0,18_1,19_0 (id_list = [0, 2, 4, 7, 8, 11, 13, 15, 17, 18, 21, 22, 25, 26, 28, 30, 33, 34, 37, 38])\n",
      "INFO:tensorflow:label: 0_0,1_0,2_0,3_1,4_0,5_1,6_1,7_1,8_1,9_0,10_1,11_0,12_1,13_0,14_0,15_0,16_1,17_0,18_1,19_0 (id = [1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0])\n"
     ]
    }
   ],
   "source": [
    "if FLAGS.do_eval:\n",
    "    eval_examples = get_dev_examples(data_dir)\n",
    "    if FLAGS.use_tpu:\n",
    "        while len(eval_examples) % FLAGS.eval_batch_size != 0:\n",
    "            eval_examples.append(PaddingInputExample())\n",
    "    eval_file = os.path.join(output_dir, \"eval.tf_record\")\n",
    "    file_based_convert_examples_to_features(eval_examples, label_list=label_list,max_seq_length=FLAGS.max_seq_length, tokenizer=tokenizer, \n",
    "                                            output_file=eval_file)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fd22fb74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:***** Running evaluation *****\n",
      "INFO:tensorflow:  Num examples = 100 (100 actual, 0 padding)\n",
      "INFO:tensorflow:  Batch size = 8\n"
     ]
    }
   ],
   "source": [
    "num_actual_eval_examples = len(eval_examples)\n",
    "tf.logging.info(\"***** Running evaluation *****\")\n",
    "tf.logging.info(\"  Num examples = %d (%d actual, %d padding)\",len(eval_examples), num_actual_eval_examples,\n",
    "                        len(eval_examples) - num_actual_eval_examples)\n",
    "tf.logging.info(\"  Batch size = %d\", FLAGS.eval_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "07f0e02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_steps = None\n",
    "if FLAGS.use_tpu:\n",
    "    assert len(eval_examples) % FLAGS.eval_batch_size == 0\n",
    "    eval_steps = int(len(eval_examples) // FLAGS.eval_batch_size)\n",
    "eval_drop_remainder = True if FLAGS.use_tpu else False\n",
    "eval_input_fn = file_based_input_fn_builder(input_file=eval_file,seq_length=FLAGS.max_seq_length,is_training=False,\n",
    "            drop_remainder=eval_drop_remainder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ab05c7f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\u1111995\\.conda\\envs\\Python\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From C:\\Users\\u1111995\\AppData\\Local\\Temp/ipykernel_17112/2590143856.py:38: map_and_batch (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.experimental.map_and_batch(...)`.\n",
      "WARNING:tensorflow:From C:\\Users\\u1111995\\.conda\\envs\\Python\\lib\\site-packages\\tensorflow_core\\contrib\\data\\python\\ops\\batching.py:276: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation.\n",
      "WARNING:tensorflow:From C:\\Users\\u1111995\\.conda\\envs\\Python\\lib\\site-packages\\tensorflow_core\\python\\autograph\\converters\\directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\u1111995\\AppData\\Local\\Temp/ipykernel_17112/2590143856.py:20: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Running eval on CPU\n",
      "INFO:tensorflow:*** Features ***\n",
      "INFO:tensorflow:  name = input_ids, shape = (?, 512)\n",
      "INFO:tensorflow:  name = input_mask, shape = (?, 512)\n",
      "INFO:tensorflow:  name = is_real_example, shape = (?,)\n",
      "INFO:tensorflow:  name = label_ids, shape = (?, 40)\n",
      "INFO:tensorflow:  name = segment_ids, shape = (?, 512)\n",
      "WARNING:tensorflow:From C:\\Users\\u1111995\\.conda\\envs\\Python\\lib\\site-packages\\bert\\modeling.py:233: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.Dense instead.\n",
      "WARNING:tensorflow:From C:\\Users\\u1111995\\.conda\\envs\\Python\\lib\\site-packages\\tensorflow_core\\python\\layers\\core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:From C:\\Users\\u1111995\\AppData\\Local\\Temp/ipykernel_17112/2746529505.py:15: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\u1111995\\AppData\\Local\\Temp/ipykernel_17112/2746529505.py:22: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\u1111995\\.conda\\envs\\Python\\lib\\site-packages\\tensorflow_core\\python\\ops\\nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\u1111995\\AppData\\Local\\Temp/ipykernel_17112/4215351563.py:29: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\u1111995\\AppData\\Local\\Temp/ipykernel_17112/4215351563.py:43: The name tf.train.init_from_checkpoint is deprecated. Please use tf.compat.v1.train.init_from_checkpoint instead.\n",
      "\n",
      "INFO:tensorflow:**** Trainable Variables ****\n",
      "INFO:tensorflow:  name = bert/embeddings/word_embeddings:0, shape = (30522, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/embeddings/token_type_embeddings:0, shape = (2, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/embeddings/position_embeddings:0, shape = (512, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/embeddings/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/embeddings/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/pooler/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/pooler/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = output_weights:0, shape = (40, 768)\n",
      "INFO:tensorflow:  name = output_bias:0, shape = (40,)\n",
      "WARNING:tensorflow:From C:\\Users\\u1111995\\AppData\\Local\\Temp/ipykernel_17112/4215351563.py:82: The name tf.logging.debug is deprecated. Please use tf.compat.v1.logging.debug instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\u1111995\\AppData\\Local\\Temp/ipykernel_17112/4215351563.py:84: The name tf.metrics.accuracy is deprecated. Please use tf.compat.v1.metrics.accuracy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\u1111995\\AppData\\Local\\Temp/ipykernel_17112/4215351563.py:88: The name tf.metrics.mean is deprecated. Please use tf.compat.v1.metrics.mean instead.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2022-05-10T15:41:35Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\u1111995\\Desktop\\project 2\\Output8\\model.ckpt-225\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2022-05-10-15:43:34\n",
      "INFO:tensorflow:Saving dict for global step 225: eval_accuracy = 0.9800000190734863, eval_loss = 0.46788707, global_step = 225, loss = 0.46499076\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 225: C:\\Users\\u1111995\\Desktop\\project 2\\Output8\\model.ckpt-225\n",
      "INFO:tensorflow:evaluation_loop marked as finished\n"
     ]
    }
   ],
   "source": [
    "result = estimator.evaluate(input_fn=eval_input_fn, steps=eval_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d8431d",
   "metadata": {},
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b7a87e1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:***** Eval results *****\n",
      "INFO:tensorflow:  eval_accuracy = 0.9800000190734863\n",
      "INFO:tensorflow:  eval_loss = 0.46788707\n",
      "INFO:tensorflow:  global_step = 225\n",
      "INFO:tensorflow:  loss = 0.46499076\n"
     ]
    }
   ],
   "source": [
    "output_eval_file = os.path.join(output_dir, \"test_results.txt\")\n",
    "with tf.io.gfile.GFile(output_eval_file, \"w\") as writer:\n",
    "    tf.logging.info(\"***** Eval results *****\")\n",
    "    for key in sorted(result.keys()):\n",
    "        tf.logging.info(\"  %s = %s\", key, str(result[key]))\n",
    "        writer.write(\"%s = %s\\n\" % (key, str(result[key])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "035fb45d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'f' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17112/4058002314.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'f' is not defined"
     ]
    }
   ],
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91fcf783",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "afb6c160",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>articleID</th>\n",
       "      <th>notes</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>223</td>\n",
       "      <td>S0365-66912012000700003-1</td>\n",
       "      <td>A 32-year-old male with colonic neoplasia with...</td>\n",
       "      <td>0_0,1_0,2_0,3_1,4_0,5_0,6_0,7_0,8_0,9_0,10_0,1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>258</td>\n",
       "      <td>S1130-01082005001200011-1</td>\n",
       "      <td>A 58-year-old man presented to his reference h...</td>\n",
       "      <td>0_0,1_0,2_0,3_1,4_0,5_0,6_1,7_1,8_0,9_0,10_0,1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>341</td>\n",
       "      <td>S1130-05582017000300150-2</td>\n",
       "      <td>An 8-year-old female patient with increased le...</td>\n",
       "      <td>0_0,1_0,2_0,3_0,4_0,5_1,6_0,7_0,8_0,9_0,10_0,1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>207</td>\n",
       "      <td>S0365-66912008000700008-1</td>\n",
       "      <td>A 64-year-old male presented with an emergency...</td>\n",
       "      <td>0_0,1_0,2_0,3_0,4_0,5_0,6_1,7_1,8_0,9_0,10_0,1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>267</td>\n",
       "      <td>S1130-01082007001100009-1</td>\n",
       "      <td>A 42-year-old woman was studied in Gastroenter...</td>\n",
       "      <td>0_0,1_0,2_0,3_1,4_0,5_0,6_0,7_0,8_1,9_0,10_0,1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>8</td>\n",
       "      <td>S0004-06142006000200014-1</td>\n",
       "      <td>A 36-year-old male, with no personal history o...</td>\n",
       "      <td>0_0,1_0,2_0,3_0,4_1,5_0,6_0,7_1,8_0,9_0,10_0,1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>45</td>\n",
       "      <td>S0004-06142010000100015-1</td>\n",
       "      <td>A 42-year-old man presented with a 2-month his...</td>\n",
       "      <td>0_0,1_0,2_0,3_0,4_1,5_0,6_0,7_0,8_0,9_0,10_0,1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>117</td>\n",
       "      <td>S0211-69952013000500035-1</td>\n",
       "      <td>We report the case of a 64-year-old man with n...</td>\n",
       "      <td>0_0,1_0,2_0,3_1,4_1,5_0,6_0,7_1,8_0,9_1,10_0,1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>205</td>\n",
       "      <td>S0365-66912008000100007-2</td>\n",
       "      <td>A girl of 11 years and 10 months old.\\nNormal ...</td>\n",
       "      <td>0_0,1_0,2_1,3_0,4_0,5_0,6_1,7_0,8_0,9_0,10_0,1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>335</td>\n",
       "      <td>S1130-05582015000400010-1</td>\n",
       "      <td>An 80-year-old woman presented to the clinic w...</td>\n",
       "      <td>0_0,1_0,2_0,3_1,4_1,5_1,6_0,7_1,8_0,9_0,10_0,1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0                  articleID  \\\n",
       "0          223  S0365-66912012000700003-1   \n",
       "1          258  S1130-01082005001200011-1   \n",
       "2          341  S1130-05582017000300150-2   \n",
       "3          207  S0365-66912008000700008-1   \n",
       "4          267  S1130-01082007001100009-1   \n",
       "..         ...                        ...   \n",
       "95           8  S0004-06142006000200014-1   \n",
       "96          45  S0004-06142010000100015-1   \n",
       "97         117  S0211-69952013000500035-1   \n",
       "98         205  S0365-66912008000100007-2   \n",
       "99         335  S1130-05582015000400010-1   \n",
       "\n",
       "                                                notes  \\\n",
       "0   A 32-year-old male with colonic neoplasia with...   \n",
       "1   A 58-year-old man presented to his reference h...   \n",
       "2   An 8-year-old female patient with increased le...   \n",
       "3   A 64-year-old male presented with an emergency...   \n",
       "4   A 42-year-old woman was studied in Gastroenter...   \n",
       "..                                                ...   \n",
       "95  A 36-year-old male, with no personal history o...   \n",
       "96  A 42-year-old man presented with a 2-month his...   \n",
       "97  We report the case of a 64-year-old man with n...   \n",
       "98  A girl of 11 years and 10 months old.\\nNormal ...   \n",
       "99  An 80-year-old woman presented to the clinic w...   \n",
       "\n",
       "                                                label  \n",
       "0   0_0,1_0,2_0,3_1,4_0,5_0,6_0,7_0,8_0,9_0,10_0,1...  \n",
       "1   0_0,1_0,2_0,3_1,4_0,5_0,6_1,7_1,8_0,9_0,10_0,1...  \n",
       "2   0_0,1_0,2_0,3_0,4_0,5_1,6_0,7_0,8_0,9_0,10_0,1...  \n",
       "3   0_0,1_0,2_0,3_0,4_0,5_0,6_1,7_1,8_0,9_0,10_0,1...  \n",
       "4   0_0,1_0,2_0,3_1,4_0,5_0,6_0,7_0,8_1,9_0,10_0,1...  \n",
       "..                                                ...  \n",
       "95  0_0,1_0,2_0,3_0,4_1,5_0,6_0,7_1,8_0,9_0,10_0,1...  \n",
       "96  0_0,1_0,2_0,3_0,4_1,5_0,6_0,7_0,8_0,9_0,10_0,1...  \n",
       "97  0_0,1_0,2_0,3_1,4_1,5_0,6_0,7_1,8_0,9_1,10_0,1...  \n",
       "98  0_0,1_0,2_1,3_0,4_0,5_0,6_1,7_0,8_0,9_0,10_0,1...  \n",
       "99  0_0,1_0,2_0,3_1,4_1,5_1,6_0,7_1,8_0,9_0,10_0,1...  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv(os.path.join(data_dir, \"codietest16.tsv\"),sep=\"\\t\")\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4cfe56d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_examples(data_dir):\n",
    "    return _create_examples(test, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ab5f93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "65dea063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 0 of 100\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:guid: test-0\n",
      "INFO:tensorflow:tokens: [CLS] a 32 - year - old male with colon ##ic neo ##pl ##asia with liver , retro ##per ##ito ##nea ##l and media ##sti ##nal meta ##sta ##ses , with a rapid evolution over a background of ul ##cera ##tive coli ##tis . one week after diagnosis , despite presenting an advanced stage , the patient was admitted for surgical intervention with partial tumor res ##ection . post ##oper ##ative chemotherapy was initiated with different consecutive therapeutic lines ox ##ali ##pl ##atin + fox ##ali ##pl ##atin + fox ##ac ##ill ##in . the k - ras gene was even determined for possible treatment with ce ##tu ##xi ##ma ##b or pan ##it ##um ##uma ##b , being negative , and therefore ruling out this therapeutic alternative . moreover , treatment with bei ##zu ##ma ##b is not ad ##vis ##able because it drains into the abdominal cavity , producing pu ##ru ##lent material . fifteen days after surgery , the patient complained of moderate left eye pain , so they requested a consultation in our service . a , but above all , there is moderate lateral ed ##ema of the con ##jun ##ct ##iva ##l mo ##tility , severe non - red ##ucible ex ##op ##ht ##hal ##mos , complete pt ##osis in the left eye , and limitation of eye gaze in all cases cr ##anial and orbital magnetic resonance imaging ( mri ) with t ##1 - weighted images and diffusion - weighted axial and flair images were requested . two nod ##ular lesions are observed in the left orbit ##a , one of them 2 ##× ##1 ##cm , located in the upper region , affecting the upper rec ##tus muscles and elevator of the eye ##lid highly suggest ##ive of meta ##sta ##sis to the second rec ##tum . 1 . due to the patient ' s poor general condition , radio ##therapy was ruled out and methyl ##pre ##d ##nis ##olo ##ne bo ##lus ##es were initiated at a dose of 1 ##g / day , with partial pain relief . however , 48 hours after the second bo ##lus of co ##rti ##cos ##ter ##oid therapy , the patient developed extreme abdominal and o ##cular pain , so se ##dation was decided and the patient died . [SEP]\n",
      "INFO:tensorflow:input_ids: 101 1037 3590 1011 2095 1011 2214 3287 2007 16844 2594 9253 24759 15396 2007 11290 1010 22307 4842 9956 22084 2140 1998 2865 16643 12032 18804 9153 8583 1010 2007 1037 5915 6622 2058 1037 4281 1997 17359 19357 6024 27441 7315 1012 2028 2733 2044 11616 1010 2750 10886 2019 3935 2754 1010 1996 5776 2001 4914 2005 11707 8830 2007 7704 13656 24501 18491 1012 2695 25918 8082 27144 2001 7531 2007 2367 5486 17261 3210 23060 11475 24759 20363 1009 4419 11475 24759 20363 1009 4419 6305 8591 2378 1012 1996 1047 1011 20710 4962 2001 2130 4340 2005 2825 3949 2007 8292 8525 9048 2863 2497 2030 6090 4183 2819 12248 2497 1010 2108 4997 1010 1998 3568 6996 2041 2023 17261 4522 1012 9308 1010 3949 2007 21388 9759 2863 2497 2003 2025 4748 11365 3085 2138 2009 18916 2046 1996 21419 17790 1010 5155 16405 6820 16136 3430 1012 5417 2420 2044 5970 1010 1996 5776 10865 1997 8777 2187 3239 3255 1010 2061 2027 7303 1037 16053 1999 2256 2326 1012 1037 1010 2021 2682 2035 1010 2045 2003 8777 11457 3968 14545 1997 1996 9530 19792 6593 11444 2140 9587 18724 1010 5729 2512 1011 2417 21104 4654 7361 11039 8865 15530 1010 3143 13866 12650 1999 1996 2187 3239 1010 1998 22718 1997 3239 3657 1999 2035 3572 13675 27532 1998 13943 8060 17011 12126 1006 27011 1007 2007 1056 2487 1011 18215 4871 1998 19241 1011 18215 26819 1998 22012 4871 2020 7303 1012 2048 7293 7934 22520 2024 5159 1999 1996 2187 8753 2050 1010 2028 1997 2068 1016 26306 2487 27487 1010 2284 1999 1996 3356 2555 1010 12473 1996 3356 28667 5809 6650 1998 7764 1997 1996 3239 21273 3811 6592 3512 1997 18804 9153 6190 2000 1996 2117 28667 11667 1012 1015 1012 2349 2000 1996 5776 1005 1055 3532 2236 4650 1010 2557 20900 2001 5451 2041 1998 25003 28139 2094 8977 12898 2638 8945 7393 2229 2020 7531 2012 1037 13004 1997 1015 2290 1013 2154 1010 2007 7704 3255 4335 1012 2174 1010 4466 2847 2044 1996 2117 8945 7393 1997 2522 28228 13186 3334 9314 7242 1010 1996 5776 2764 6034 21419 1998 1051 15431 3255 1010 2061 7367 20207 2001 2787 1998 1996 5776 2351 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:label: 0_0,1_0,2_0,3_1,4_0,5_0,6_0,7_0,8_0,9_0,10_0,11_0,12_0,13_0,14_1,15_0,16_1,17_1,18_0,19_0 (id_list = [0, 2, 4, 7, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 29, 30, 33, 35, 36, 38])\n",
      "INFO:tensorflow:label: 0_0,1_0,2_0,3_1,4_0,5_0,6_0,7_0,8_0,9_0,10_0,11_0,12_0,13_0,14_1,15_0,16_1,17_1,18_0,19_0 (id = [1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0])\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:guid: test-1\n",
      "INFO:tensorflow:tokens: [CLS] a 58 - year - old man presented to his reference hospital in 1999 with a history of chronic intra ##ctable dia ##rr ##hea accompanied by weight loss . the patient was diagnosed with cd and a g ##lu ##ten - free diet was established . she did not report any other relevant history and the physical examination was negative . among the family history , one patient ' s sister and two nephew ##s also had a newly diagnosed cd , with a good response to a g ##lu ##ten - free diet . analytical and bio ##chemical data performed on the patient , including thyroid hormones , vitamin b - 2 and calcium levels , as well as determination of fe ##cal fat and ser ##ological analysis were normal . she had negative anti - g ##lia ##din and anti - trans ##gl ##uta ##mina ##se antibodies and weakly positive anti - end ##omy ##si ##um antibodies ( 1 / 10 ) and positive anti - ne ##ut ##rop ##hil cy ##top ##las ##mic antibodies ( 1 smooth and anti - smoking ) . h ##la typing was positive for dq ##2 ( h ##la - dq ##a1 * 050 ##2 and dq ##b ##1 * 02 ##01 ) . the d - x ##yl ##osa absorption test was normal . his ##to ##logical study of duo ##den ##al bio ##ps ##ies showed total ve ##sic ##ular lesions ( marsh grade 3 ##c ) and an important sub ##mu ##cos ##al inflammatory infiltrate composed of l ##ym ##ph ##ocytes . the patient was diagnosed with cd and treated with a g ##lu ##ten - free diet . the patient had a good digest ##ive clinical response , with disappearance of the dia ##rr ##hea and significant weight gain to its usual level . a new duo ##den ##al bio ##psy performed one year after diagnosis showed significant his ##to ##logical improvement persist ##ing mild duo ##den ##al vi ##llo ##us ( marsh type 3a ) with a marked decrease in sub ##mu ##cos ##al l ##ym ##ph ##oc ##ytic inflammatory infiltrate . eighteen months after the diagnosis , the patient began to present frequent falls to the vent ##ila ##tor without loss of consciousness due to abnormal movements in the right ear . he was conscious and oriented and o ##cular movements and cr ##anial nerve examination were normal . he had d ##ys ##arth ##ria and associated hyper ##re ##fle ##xia , together with spontaneous my ##oc ##lon ##us caused by ta ##ct ##ile stimuli in right foot and foot . walking is seriously compromised due to the presence of my ##oc ##lon ##us , requiring help for self - care , supporting someone else so as not to fall . muscle tone and strength were preserved . ne ##uro ##psy ##cho ##logical examination showed normal levels of language and verbal memory , with slight impairment of visual memory . magnetic resonance imaging ( mri ) and po ##sit ##ron emission tom ##ography ( pet ) were [SEP]\n",
      "INFO:tensorflow:input_ids: 101 1037 5388 1011 2095 1011 2214 2158 3591 2000 2010 4431 2902 1999 2639 2007 1037 2381 1997 11888 26721 23576 22939 12171 20192 5642 2011 3635 3279 1012 1996 5776 2001 11441 2007 3729 1998 1037 1043 7630 6528 1011 2489 8738 2001 2511 1012 2016 2106 2025 3189 2151 2060 7882 2381 1998 1996 3558 7749 2001 4997 1012 2426 1996 2155 2381 1010 2028 5776 1005 1055 2905 1998 2048 7833 2015 2036 2018 1037 4397 11441 3729 1010 2007 1037 2204 3433 2000 1037 1043 7630 6528 1011 2489 8738 1012 17826 1998 16012 15869 2951 2864 2006 1996 5776 1010 2164 29610 20752 1010 17663 1038 1011 1016 1998 13853 3798 1010 2004 2092 2004 9128 1997 10768 9289 6638 1998 14262 10091 4106 2020 3671 1012 2016 2018 4997 3424 1011 1043 6632 8718 1998 3424 1011 9099 23296 13210 22311 3366 22931 1998 17541 3893 3424 1011 2203 16940 5332 2819 22931 1006 1015 1013 2184 1007 1998 3893 3424 1011 11265 4904 18981 19466 22330 14399 8523 7712 22931 1006 1015 5744 1998 3424 1011 9422 1007 1012 1044 2721 22868 2001 3893 2005 25410 2475 1006 1044 2721 1011 25410 27717 1008 28714 2475 1998 25410 2497 2487 1008 6185 24096 1007 1012 1996 1040 1011 1060 8516 8820 16326 3231 2001 3671 1012 2010 3406 9966 2817 1997 6829 4181 2389 16012 4523 3111 3662 2561 2310 19570 7934 22520 1006 9409 3694 1017 2278 1007 1998 2019 2590 4942 12274 13186 2389 20187 29543 3605 1997 1048 24335 8458 28788 1012 1996 5776 2001 11441 2007 3729 1998 5845 2007 1037 1043 7630 6528 1011 2489 8738 1012 1996 5776 2018 1037 2204 17886 3512 6612 3433 1010 2007 13406 1997 1996 22939 12171 20192 1998 3278 3635 5114 2000 2049 5156 2504 1012 1037 2047 6829 4181 2389 16012 18075 2864 2028 2095 2044 11616 3662 3278 2010 3406 9966 7620 29486 2075 10256 6829 4181 2389 6819 7174 2271 1006 9409 2828 23842 1007 2007 1037 4417 9885 1999 4942 12274 13186 2389 1048 24335 8458 10085 21252 20187 29543 1012 7763 2706 2044 1996 11616 1010 1996 5776 2211 2000 2556 6976 4212 2000 1996 18834 11733 4263 2302 3279 1997 8298 2349 2000 19470 5750 1999 1996 2157 4540 1012 2002 2001 9715 1998 8048 1998 1051 15431 5750 1998 13675 27532 9113 7749 2020 3671 1012 2002 2018 1040 7274 22425 4360 1998 3378 23760 2890 21031 14787 1010 2362 2007 17630 2026 10085 7811 2271 3303 2011 11937 6593 9463 22239 1999 2157 3329 1998 3329 1012 3788 2003 5667 20419 2349 2000 1996 3739 1997 2026 10085 7811 2271 1010 9034 2393 2005 2969 1011 2729 1010 4637 2619 2842 2061 2004 2025 2000 2991 1012 6740 4309 1998 3997 2020 6560 1012 11265 10976 18075 9905 9966 7749 3662 3671 3798 1997 2653 1998 12064 3638 1010 2007 7263 25172 1997 5107 3638 1012 8060 17011 12126 1006 27011 1007 1998 13433 28032 4948 15760 3419 9888 1006 9004 1007 2020 102\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:label: 0_0,1_0,2_0,3_1,4_0,5_0,6_1,7_1,8_0,9_0,10_0,11_0,12_0,13_0,14_0,15_0,16_1,17_0,18_0,19_0 (id_list = [0, 2, 4, 7, 8, 10, 13, 15, 16, 18, 20, 22, 24, 26, 28, 30, 33, 34, 36, 38])\n",
      "INFO:tensorflow:label: 0_0,1_0,2_0,3_1,4_0,5_0,6_1,7_1,8_0,9_0,10_0,11_0,12_0,13_0,14_0,15_0,16_1,17_0,18_0,19_0 (id = [1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0])\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:guid: test-2\n",
      "INFO:tensorflow:tokens: [CLS] an 8 - year - old female patient with increased left hem ##iman ##di ##bular volume , 5 months of evolution , rapid growth , painful . intra ##ora ##l expansion of bu ##cca ##l co ##rti ##cal with displacement of dental organs . radio ##graphic ##ally , the les ##ion manifest ##s as part of the left body and man ##di ##bular ram ##us , but preserves the con ##dy ##le and co ##ron ##oid process . result of inc ##ision ##al bio ##psy , pl ##ex ##iform am ##elo ##bla ##sto ##ma of the man ##di ##ble . taking into account the local aggressive clinical behavior of the les ##ion , block ex ##cision is performed . a reconstruction pro ##st ##hesis was placed preserving the con ##dy ##le and co ##ron ##oid process . post ##oper ##ative period was uneven ##tf ##ul . neurological ( inferior ) and motor structures are preserved . good oral opening and adequate facial appearance . three months after the initial surgery , a bone matrix mixed with bone marrow as ##pi ##rate was placed in a surgical bed in an attempt to stimulate bone growth in the surgical bed , observing adequate bone neo ##form ##ation to date with acceptable dental o ##cc ##lusion . good mouth opening , facial aesthetics , as well as sensitivity and motor conservation . five years of follow - up without complications . [SEP]\n",
      "INFO:tensorflow:input_ids: 101 2019 1022 1011 2095 1011 2214 2931 5776 2007 3445 2187 19610 18505 4305 28808 3872 1010 1019 2706 1997 6622 1010 5915 3930 1010 9145 1012 26721 6525 2140 4935 1997 20934 16665 2140 2522 28228 9289 2007 13508 1997 11394 11595 1012 2557 14773 3973 1010 1996 4649 3258 19676 2015 2004 2112 1997 1996 2187 2303 1998 2158 4305 28808 8223 2271 1010 2021 18536 1996 9530 5149 2571 1998 2522 4948 9314 2832 1012 2765 1997 4297 19969 2389 16012 18075 1010 20228 10288 22631 2572 18349 28522 16033 2863 1997 1996 2158 4305 3468 1012 2635 2046 4070 1996 2334 9376 6612 5248 1997 1996 4649 3258 1010 3796 4654 28472 2003 2864 1012 1037 8735 4013 3367 24124 2001 2872 15224 1996 9530 5149 2571 1998 2522 4948 9314 2832 1012 2695 25918 8082 2558 2001 17837 24475 5313 1012 23130 1006 14092 1007 1998 5013 5090 2024 6560 1012 2204 8700 3098 1998 11706 13268 3311 1012 2093 2706 2044 1996 3988 5970 1010 1037 5923 8185 3816 2007 5923 24960 2004 8197 11657 2001 2872 1999 1037 11707 2793 1999 2019 3535 2000 23216 5923 3930 1999 1996 11707 2793 1010 14158 11706 5923 9253 14192 3370 2000 3058 2007 11701 11394 1051 9468 24117 1012 2204 2677 3098 1010 13268 20749 1010 2004 2092 2004 14639 1998 5013 5680 1012 2274 2086 1997 3582 1011 2039 2302 12763 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:label: 0_0,1_0,2_0,3_0,4_0,5_1,6_0,7_0,8_0,9_0,10_0,11_0,12_0,13_0,14_1,15_0,16_1,17_0,18_0,19_0 (id_list = [0, 2, 4, 6, 8, 11, 12, 14, 16, 18, 20, 22, 24, 26, 29, 30, 33, 34, 36, 38])\n",
      "INFO:tensorflow:label: 0_0,1_0,2_0,3_0,4_0,5_1,6_0,7_0,8_0,9_0,10_0,11_0,12_0,13_0,14_1,15_0,16_1,17_0,18_0,19_0 (id = [1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0])\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:guid: test-3\n",
      "INFO:tensorflow:tokens: [CLS] a 64 - year - old male presented with an emergency complaint of double vision op ##ht ##hal ##mology and di ##zziness , apparently without other remarkable symptoms ; however , an unstable standing was observed , which was not justified only by dip ##lo ##pia . as the only ant ##ece ##dent of interest , the patient reported having been va ##cci ##nated against influenza for five days . visual ac ##uity was 0 . 7 in both eyes ( ao ) , and both pupils had ref ##ractive errors , with no previous contact with my ##dr ##ias ##is . the patient had a limitation in left at ##rial fi ##bri ##llation , greater in left eye ( le ) , in the su ##pr ##ad ##uc ##tion of be , and difficulty for the rest of eye movements , referring horizontal dip ##lo ##pia . the rest of the exploration was normal . 1 . the suspected diagnosis of a fisher ' s syndrome is referred to the ne ##uro ##logy service , which detect ##s ata ##xi ##c ga ##it , h ##yp ##ore ##fle ##xia , and disc ##ards weakness of the limbs and complete study admission for examination . the results of blood tests and computed tom ##ography ( ct ) performed in the emergency department were normal . twenty - four hours after admission there was a respiratory distress requiring oxygen and physical therapy , and in the following weeks new neurological symptoms were developed : facial paralysis , d ##ys ##phon ##ia and d ##ys ##pha ##gia . during admission , a lu ##mba ##r pun ##cture was performed , which revealed a terminal al ##bino ##cy ##to ##logical mal ##form ##ation , and a magnetic resonance imaging ( mri ) that ruled out a space occupying les ##ion . the electro ##my ##ographic study did not provide additional information . the im ##mun ##ological study was positive for g ##q - 1b antibody , confirming the initial diagnosis . the patient improved his symptoms two weeks after admission , having received two cycles of im ##mun ##og ##lo ##bu ##lins . the clinical course was slow and poly ##sy ##mpt ##oma ##tic , persist ##ing dip ##lo ##pia with limitation of bilateral manifestation in a prolonged way . [SEP]\n",
      "INFO:tensorflow:input_ids: 101 1037 4185 1011 2095 1011 2214 3287 3591 2007 2019 5057 12087 1997 3313 4432 6728 11039 8865 20570 1998 4487 29212 1010 4593 2302 2060 9487 8030 1025 2174 1010 2019 14480 3061 2001 5159 1010 2029 2001 2025 15123 2069 2011 16510 4135 19312 1012 2004 1996 2069 14405 26005 16454 1997 3037 1010 1996 5776 2988 2383 2042 12436 14693 23854 2114 24442 2005 2274 2420 1012 5107 9353 18518 2001 1014 1012 1021 1999 2119 2159 1006 20118 1007 1010 1998 2119 7391 2018 25416 26884 10697 1010 2007 2053 3025 3967 2007 2026 13626 7951 2483 1012 1996 5776 2018 1037 22718 1999 2187 2012 14482 10882 23736 20382 1010 3618 1999 2187 3239 1006 3393 1007 1010 1999 1996 10514 18098 4215 14194 3508 1997 2022 1010 1998 7669 2005 1996 2717 1997 3239 5750 1010 7727 9876 16510 4135 19312 1012 1996 2717 1997 1996 8993 2001 3671 1012 1015 1012 1996 6878 11616 1997 1037 8731 1005 1055 8715 2003 3615 2000 1996 11265 10976 6483 2326 1010 2029 11487 2015 29533 9048 2278 11721 4183 1010 1044 22571 5686 21031 14787 1010 1998 5860 18117 11251 1997 1996 10726 1998 3143 2817 9634 2005 7749 1012 1996 3463 1997 2668 5852 1998 24806 3419 9888 1006 14931 1007 2864 1999 1996 5057 2533 2020 3671 1012 3174 1011 2176 2847 2044 9634 2045 2001 1037 16464 12893 9034 7722 1998 3558 7242 1010 1998 1999 1996 2206 3134 2047 23130 8030 2020 2764 1024 13268 26287 1010 1040 7274 20846 2401 1998 1040 7274 21890 10440 1012 2076 9634 1010 1037 11320 11201 2099 26136 14890 2001 2864 1010 2029 3936 1037 5536 2632 21891 5666 3406 9966 15451 14192 3370 1010 1998 1037 8060 17011 12126 1006 27011 1007 2008 5451 2041 1037 2686 13992 4649 3258 1012 1996 16175 8029 13705 2817 2106 2025 3073 3176 2592 1012 1996 10047 23041 10091 2817 2001 3893 2005 1043 4160 1011 26314 27781 1010 19195 1996 3988 11616 1012 1996 5776 5301 2010 8030 2048 3134 2044 9634 1010 2383 2363 2048 12709 1997 10047 23041 8649 4135 8569 24412 1012 1996 6612 2607 2001 4030 1998 26572 6508 27718 9626 4588 1010 29486 2075 16510 4135 19312 2007 22718 1997 17758 24491 1999 1037 15330 2126 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:label: 0_0,1_0,2_0,3_0,4_0,5_0,6_1,7_1,8_0,9_0,10_0,11_0,12_0,13_0,14_0,15_0,16_1,17_1,18_0,19_0 (id_list = [0, 2, 4, 6, 8, 10, 13, 15, 16, 18, 20, 22, 24, 26, 28, 30, 33, 35, 36, 38])\n",
      "INFO:tensorflow:label: 0_0,1_0,2_0,3_0,4_0,5_0,6_1,7_1,8_0,9_0,10_0,11_0,12_0,13_0,14_0,15_0,16_1,17_1,18_0,19_0 (id = [1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0])\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:guid: test-4\n",
      "INFO:tensorflow:tokens: [CLS] a 42 - year - old woman was studied in gas ##tro ##enter ##ology consultation ##s since january 2005 because she presented with low rec ##tal bleeding at the end of the deposition , together with ten ##es ##mus and anal pain of two years duration . the patient had no family or personal history of interest and did not follow any medical treatment routinely . physical examination revealed only an ind ##ura ##ted area in the left lateral wall of the rec ##tum on rec ##tal examination . a complete blood test was performed which was severely normal . 2 lesions were located on the right side of the rec ##tum . the differential diagnosis between inflammatory bow ##el disease ( ul ##cera ##tive coli ##tis ) , ste ##rco ##rar ##ean ul ##cer and solitary rec ##tal ul ##cer syndrome was initially proposed . pathology showed mu ##cos ##al thick ##ening , el ##onga ##tion and distortion of the glands and lam ##ina prop ##ria with a large amount of rec ##tal col ##lage ##n ed ##ema , all of which was compatible with the ul ##cer diagnosis of the ul ##cer syndrome . rec ##tal an ##ore ##cta ##l mantle volume was performed , showing a slightly reduced to ##ler ##able maximum volume and a minimal ##ly extended balloon time . [SEP]\n",
      "INFO:tensorflow:input_ids: 101 1037 4413 1011 2095 1011 2214 2450 2001 3273 1999 3806 13181 29110 6779 16053 2015 2144 2254 2384 2138 2016 3591 2007 2659 28667 9080 9524 2012 1996 2203 1997 1996 19806 1010 2362 2007 2702 2229 7606 1998 20302 3255 1997 2048 2086 9367 1012 1996 5776 2018 2053 2155 2030 3167 2381 1997 3037 1998 2106 2025 3582 2151 2966 3949 19974 1012 3558 7749 3936 2069 2019 27427 4648 3064 2181 1999 1996 2187 11457 2813 1997 1996 28667 11667 2006 28667 9080 7749 1012 1037 3143 2668 3231 2001 2864 2029 2001 8949 3671 1012 1016 22520 2020 2284 2006 1996 2157 2217 1997 1996 28667 11667 1012 1996 11658 11616 2090 20187 6812 2884 4295 1006 17359 19357 6024 27441 7315 1007 1010 26261 29566 19848 11219 17359 17119 1998 14348 28667 9080 17359 17119 8715 2001 3322 3818 1012 19314 3662 14163 13186 2389 4317 7406 1010 3449 26356 3508 1998 20870 1997 1996 23340 1998 16983 3981 17678 4360 2007 1037 2312 3815 1997 28667 9080 8902 20679 2078 3968 14545 1010 2035 1997 2029 2001 11892 2007 1996 17359 17119 11616 1997 1996 17359 17119 8715 1012 28667 9080 2019 5686 25572 2140 16019 3872 2001 2864 1010 4760 1037 3621 4359 2000 3917 3085 4555 3872 1998 1037 10124 2135 3668 13212 2051 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:label: 0_0,1_0,2_0,3_1,4_0,5_0,6_0,7_0,8_1,9_0,10_0,11_0,12_0,13_0,14_0,15_0,16_1,17_0,18_0,19_0 (id_list = [0, 2, 4, 7, 8, 10, 12, 14, 17, 18, 20, 22, 24, 26, 28, 30, 33, 34, 36, 38])\n",
      "INFO:tensorflow:label: 0_0,1_0,2_0,3_1,4_0,5_0,6_0,7_0,8_1,9_0,10_0,11_0,12_0,13_0,14_0,15_0,16_1,17_0,18_0,19_0 (id = [1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0])\n"
     ]
    }
   ],
   "source": [
    "if FLAGS.do_predict:\n",
    "        predict_examples = get_test_examples(data_dir)\n",
    "        num_actual_predict_examples = len(predict_examples)\n",
    "        if FLAGS.use_tpu:\n",
    "            while len(predict_examples) % FLAGS.predict_batch_size != 0:\n",
    "                predict_examples.append(PaddingInputExample())\n",
    "\n",
    "        predict_file = os.path.join(output_dir, \"predict.tf_record\")\n",
    "        file_based_convert_examples_to_features(predict_examples, label_list,\n",
    "                                                FLAGS.max_seq_length, tokenizer,\n",
    "                                                predict_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e79693f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:***** Running prediction*****\n",
      "INFO:tensorflow:  Num examples = 100 (100 actual, 0 padding)\n",
      "INFO:tensorflow:  Batch size = 8\n"
     ]
    }
   ],
   "source": [
    "tf.logging.info(\"***** Running prediction*****\")\n",
    "tf.logging.info(\"  Num examples = %d (%d actual, %d padding)\",\n",
    "                        len(predict_examples), num_actual_predict_examples,\n",
    "                        len(predict_examples) - num_actual_predict_examples)\n",
    "tf.logging.info(\"  Batch size = %d\", FLAGS.predict_batch_size)\n",
    "\n",
    "predict_drop_remainder = True if FLAGS.use_tpu else False\n",
    "predict_input_fn = file_based_input_fn_builder(\n",
    "            input_file=predict_file,\n",
    "            seq_length=FLAGS.max_seq_length,\n",
    "            is_training=False,\n",
    "            drop_remainder=predict_drop_remainder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a1b0dd55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:prediction_loop marked as finished\n"
     ]
    }
   ],
   "source": [
    "result1 = estimator.predict(input_fn=predict_input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "53adfc72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Running infer on CPU\n",
      "INFO:tensorflow:*** Features ***\n",
      "INFO:tensorflow:  name = input_ids, shape = (?, 512)\n",
      "INFO:tensorflow:  name = input_mask, shape = (?, 512)\n",
      "INFO:tensorflow:  name = is_real_example, shape = (?,)\n",
      "INFO:tensorflow:  name = label_ids, shape = (?, 40)\n",
      "INFO:tensorflow:  name = segment_ids, shape = (?, 512)\n",
      "INFO:tensorflow:**** Trainable Variables ****\n",
      "INFO:tensorflow:  name = bert/embeddings/word_embeddings:0, shape = (30522, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/embeddings/token_type_embeddings:0, shape = (2, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/embeddings/position_embeddings:0, shape = (512, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/embeddings/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/embeddings/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/pooler/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/pooler/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = output_weights:0, shape = (40, 768)\n",
      "INFO:tensorflow:  name = output_bias:0, shape = (40,)\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\u1111995\\Desktop\\project 2\\Output8\\model.ckpt-225\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "outputs = [list(next(result1).values())[0] for i in range(100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "18839ade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.9668534 , 0.02772105, 0.6758409 , 0.3482182 , 0.8649518 ,\n",
       "       0.13742259, 0.59318393, 0.40129864, 0.63186234, 0.3400343 ,\n",
       "       0.73278135, 0.2743978 , 0.82844096, 0.18083379, 0.50106436,\n",
       "       0.5118963 , 0.7556841 , 0.23564705, 0.7041823 , 0.27380043,\n",
       "       0.92050904, 0.08488429, 0.7450615 , 0.2723015 , 0.8092759 ,\n",
       "       0.19038063, 0.80323756, 0.20033771, 0.6630727 , 0.35012436,\n",
       "       0.9523307 , 0.03944254, 0.14513579, 0.8553724 , 0.79804224,\n",
       "       0.19140103, 0.7500935 , 0.2134487 , 0.95894563, 0.03178847],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e1f9724b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b39d617e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_arr = np.asarray(outputs, np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f8e005f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1.,\n",
       "       0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 1.,\n",
       "       1., 0., 1., 0., 1., 0.], dtype=float32)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B = np.where(np_arr > 0.5, 1, 0)\n",
    "prediction = np.asarray(B,np.float32)\n",
    "prediction[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9dd8d941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Running infer on CPU\n",
      "INFO:tensorflow:*** Features ***\n",
      "INFO:tensorflow:  name = input_ids, shape = (?, 512)\n",
      "INFO:tensorflow:  name = input_mask, shape = (?, 512)\n",
      "INFO:tensorflow:  name = is_real_example, shape = (?,)\n",
      "INFO:tensorflow:  name = label_ids, shape = (?, 40)\n",
      "INFO:tensorflow:  name = segment_ids, shape = (?, 512)\n",
      "INFO:tensorflow:**** Trainable Variables ****\n",
      "INFO:tensorflow:  name = bert/embeddings/word_embeddings:0, shape = (30522, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/embeddings/token_type_embeddings:0, shape = (2, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/embeddings/position_embeddings:0, shape = (512, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/embeddings/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/embeddings/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/pooler/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/pooler/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = output_weights:0, shape = (40, 768)\n",
      "INFO:tensorflow:  name = output_bias:0, shape = (40,)\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\u1111995\\Desktop\\project 2\\Output8\\model.ckpt-225\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "labels = [list(next(result1).values())[1] for i in range(100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a11ed2d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 1., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
       "       0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 1., 1., 0., 0., 1.,\n",
       "       0., 1., 1., 0., 1., 0.], dtype=float32)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label1 = np.asarray(labels, np.float32)\n",
    "label1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "216e11a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.81875"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(prediction == label1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215012bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150bf981",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4553f196",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35389b9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
